<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>andy's blog</title><link href="/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>/</id><updated>2016-01-28T00:00:00+08:00</updated><entry><title>图形数据库-2</title><link href="/tu-xing-shu-ju-ku-2.html" rel="alternate"></link><updated>2016-01-28T00:00:00+08:00</updated><author><name>andy.zhangtao</name></author><id>tag:,2016-01-28:tu-xing-shu-ju-ku-2.html</id><summary type="html">&lt;h1&gt;图形数据库(GraphDB)2 - Graph和RDBMS的区别&lt;/h1&gt;
&lt;p&gt;&lt;br/&gt;
如果您对此文章感兴趣或者有其它不同观点，欢迎发邮件至&lt;a href="&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#116;&amp;#111;&amp;#58;&amp;#97;&amp;#110;&amp;#100;&amp;#121;&amp;#46;&amp;#122;&amp;#104;&amp;#97;&amp;#110;&amp;#103;&amp;#116;&amp;#97;&amp;#111;&amp;#64;&amp;#104;&amp;#111;&amp;#116;&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#46;&amp;#99;&amp;#111;&amp;#109;"&gt;&amp;#97;&amp;#110;&amp;#100;&amp;#121;&amp;#46;&amp;#122;&amp;#104;&amp;#97;&amp;#110;&amp;#103;&amp;#116;&amp;#97;&amp;#111;&amp;#64;&amp;#104;&amp;#111;&amp;#116;&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#46;&amp;#99;&amp;#111;&amp;#109;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
本文主要记录了目前使用最多的GraphDB-neo4j和RDBMS的区别。同时附带介绍了如何将数据从RDBMS当中迁移到Neo4j中。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
RDBMS数据库自从上个世纪80年代开始出现并且一直演进到现在，占据了数据库大多数市场份额。RDBMS强调数据是结构化的，并且通过列来表示数据的各项属性，同时用行来聚合具有相同属性的数据。而这种以结构化数据为核心的理念，非常适合计算机进行解析处理。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
在RDBMS当中，如果需要关联不同的数据，那么只能通过主外健的方式进行。换言之，有主外健最好，如果没有主外键，那么就需要额外再创建主外健关系。这样做有利有弊，有利的一方面是不会破坏数据的结构性。而弊端则是引入主外键后，会大大增加不同数据之间的模型复杂度。而增加的模型复杂度又会导致需要加大计算代码，所以对于RDBMS来说，如何优化SQL语句就是一项长期而艰巨的任务。&lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="https://lh3.googleusercontent.com/M3m83HOldFJ2rkAAoQ18cP3iyM72JxZftfUOdRyhQFzKUFZfAgPu6Fr12iL3gL9Zxwn9C0oKsD84UtWf0d6WgfXFeL1E8ueLzeEo-sC677KR49HtmpwE5gaeM0Vog8Hdxy2hqlhhGOrmBVfaC7acpjFY1LwsO0LN6nFeU65-aiCPdwF_XM1Vv0pYXSt-dysP0M1GfIhcBnzFK4EVewaCwuuUFgJS8pUxrmOCR1QyVy88FKbVC5hTJweB1e4jIagSKrHarmDbT7q4d11FXkQm23p5MdyfQx-BJ0-IcK8FL6TrK6IENVu-gEqr9GdeeeKOPVsgEbMoUXlYP1Yd7dc5VBrJLxkVoqSx6V8qxog4B35QS_3wfax1O9xNCKtiWsklOUbgbRc2LHHB28ZfRH48qXs4VsvMvfGpAmeW6eqJqZYhEk67CcSzl8EQgqhc_8V1NpMQ0f8MZhRBHtG2N8LCvFQieX7ALMW82k39OiVTPJb6-6qco2AAko6zGI2X2THjdimMoguilGzJZnEXe68DyFJNFNY6KicZi6DW9XivpZKGcY-M0mJzzZVkfxmBUHHBMeI=w1192-h632-no" /&gt;
&lt;br/&gt;
上图是一对多的情况，这种场景相对而言还容易处理。如果遇到多对多的时候怎么办呢？ 传统的做法就是将多对多的模型转化为1对多的模型，如果无法转化。那么就需要再引入一张表来单独存储多对多的关联关系。 而引入这些表之后，势必将会加大SQL语句复杂度，增大计算开销。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
尽管，目前已经有很多优化SQL的解决方案，也有很多可以简化数据模型的解决方案。但不可否认的是，因为RDBMS对于结构化数据至上的核心理念，导致在很多应用场景下，在处理这些复杂数据模型时，除了业务层面做出妥协，RDBMS没有其它好的方案。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;从RDBMS转移到GraphDB&lt;/h2&gt;
&lt;p&gt;&lt;br/&gt;
在GraphDB当中，关系是“一等公民”。GraphDB和RDBMS最大的区别就是，GraphDB不需要通过主外键，不需要强连接来表示两个实体之间的联系。GraphDB只需要将不同实体之间的关系抽象成节点之间的连接，就可以完成RDBMS当中的复杂计算。而这一点将会使用户有能力在GraphDB当中重建一个现实社会关系.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
也有观点认为，GraphDB有可能会演变为下一代的RDBMS，但在下一代的RDBMS当中，关系会取代结构化数据变为一等公民。传统RDBMS当中的主外键将会成为历史。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
在GraphDB当中，每个node都会天生拥有一些指向其它node的关系(在上一篇当中，我们提到Graph不允许存在死链，所以也就不会允许存在单独node)。这些关系通过其类型和其方向来维护，并且每个关系又可以拥有多个属性。通过这样的模型，就可以解释RDBMS当中的1对多和多对多模型。例如下图中，用户需要检索Alice的数据，那么通过Alice的关系就可以明确出检索方向，减少不必要的索引开销和计算开销。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
而这种图论模型，在海量数据场景下会体现出巨大的计算优势。在同等海量数据下，GraphDB的检索效率就可以达到秒级。而RDBMS则有可能是分钟级(仅仅是理论数据，具体情况则依赖于具体业务场景和数据量)。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
&lt;img alt="image" src="https://lh3.googleusercontent.com/yhawaQ7_SYeuJzIP8GXCthecgw6TZVObg7nrLF3KDSJylh7f_deb_g5MM6hub2reRrHlFqi-hrX5rug_0FCPaj3UisP0dnAXvq7iUSN_qi4xjoS1vORM50JkC7O4VFN_OgDh3PJ6BjBi8oARY9jrSTAMeChQ9rbhrcOCZkpQ3n8pCc7E3Mtf-h4N9z-72sbKK6xWQeNLJkk0EPIKjFuc_N0FodFw98-aFx7K5aaFPXOpKy0ZHc_UEU4a_OHG9oDs95npmlt19of_6zcJxS7razfmQgFH0-Cd9QHJW1kHLRylZfTA7TJyuRdh4qudR6skHw815VNqZQiURo5fvfSpDdbn97Kq3Ad7Rml5H6XwzI6VvaurXKYwWlSJrwIEVYBDkyIOrqTAGxDeV0Ixo2KsXdfsnSPx8Fn9sE0cCS70KPF70Sbv7hgbBQmu00Ohv0jBnRnqaP28s2R-zrev40hNni5iXaniHAnqbNcD1pdTstFXHnhVSsTh8WC5_uDhdqVj7dwRwvEe37h-pDD305SWnPO7Su4SV2qrSxILWgEYM41HlHcOsuguQMKdPrC5O5L5VZs=w493-h170-no" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
GraphDB只关心"关系"，因此不关心数据模型的颗粒度和复杂度。因此用户在使用GraphDB时就可以仿照真实世界中实体特点(小而多，个性化并且关联关系复杂)来构建数据模型。这样用户通过GraphDB就可以尽可能反映真实世界的情况。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
当我们将模型控制为细粒度时就会发现：这些模型会丧失明显的模型边界。但对于这样无明显边界的模型，GraphDB也会保证满足ACID原则。而且Neo4j也会通过日志机制和回滚机制，来保障数据一致性。简而言之，Neo4j会绝对保证提交到数据库中的数据不会丢失。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
如果用户已经熟悉了对RDBMS的使用，那么转化为使用GraphDB也不是什么难事。使用GraphDB可以从实体图开始，通过如下所示的实体图可以让所有人将精力聚焦于业务模型本事，而不用在考虑如何设计主外键。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
&lt;img alt="image" src="https://lh3.googleusercontent.com/xUyhY-AcTYj8na-n64Cgs7lsmuQuynnB6E9NlFsyexBNG9kLDXK_mpPf2FsVR5f5cMz-61QEy85QdtuLtYOGahQoSMcU1-jfVZAl2_aO2gOxWNKyhuq5K6c4VvyyHoPjerQunT64o_Gy81_WgbIqK9RmhKJ1t_3nE9Ai175khxL0yExitKvIHM_u1B7YzUamyDDvi2ZavmBTGQxXjhgBTZV77hM942_6vfv5juWxx4qmnfh6mL0Iq5QAnXESz8-Ogp19OmBHHD2XjjqyTfUaqvzjm1TRbR91Q9O-5jQiAj_k6p1_tRAr7bS5ZflOIQgXR3u8oOGJIIyKZPcQNQr3X3JuARTieDx8dol4XCxskvjAi_hx4L9aJVveg-cztAOiw7735gF2eYR3RouMr9NZg7M_QdSRGT8nXFjGtV-gYZN9HcD5JGY_fcy_RCvuqnPOmaFQzHVKTXoKgoVaPEtS4aSkrm42sqKzmwpgw9vrDVVAqLpD0Rnd8HW44kNibMQUE9H6CJ78HGivwbUydTdR3wD7tLH-h8VLu9UJA7C6as5d2eYSbEhURXbkJR5O_U0ur8k=w1207-h837-no" /&gt;
&lt;br/&gt;
为什么这么说呢？请看下图，下图同时展现了在RDBMS和GraphDB中如何来设计数据模型的。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
&lt;img alt="image" src="https://lh3.googleusercontent.com/_mQq6eg3ObVmgOfIH-Sg27jA6FOe2HS1Y_ZAqvI3vOIsRNI3W4J7rquGJyakcu315sOzlODyDLHe93yPLf_IA9w2eIb_aHyGViFZpQJFdOaPZbbHiVJJ1Dh5ZpHfaFTw5tKTmlYwGcqyFH3T9KYsR8xn2pgZxWASNe-nZ4SNXuDnKrBvxajgAdEA8CLlu3tqVzTTHREo50c1mvd4Nbg9jzDsxVZH0NONoca3hPiPJOIqEKHhmBhSk9PoA4LTefu7DNUu2HrAYCnislXYLiN1sB1l4rl337w8aDh43DfwCB78kXuHSRwPUtvE5FkGjwAsKz0uE1gcAWnNY0R8LSxmbh6mpOgzznt1RH3erUjY5TOZknpxcxrrQYUUcWYPG0i-ePIZoCxdNU83bCd-PH821-iIvlvGC5Rhi-MeVCq56xPl_JXmGqBZPOgPbdyGGeUkFs_3rhOMJvHwCRWQrHwOLi8B-b34vBYeMz7OTsz7Y1ef8XgvdmOebjzSa9FS5-tccoxpNsFRIFcUEHgrQzhOXcB6XFqyhEPGgoRlfdVfRQzRSOfgTkRIvfQMKrH6Vo8WNgM=w1502-h650-no" /&gt;
&lt;img alt="image" src="https://lh3.googleusercontent.com/HbJAPanjbCuZm4TR1NXxbRrixuBb1_zyTbYOq4zUgiegIyA19LVy6lHoq7lJM1sv-X-jimZ53nbZtLSh_JkvTOzvcSwvtvjAJJcuParaXctFL8A9nfoGQYSvRENiIaEGHbFwBxOm8fwTH_X775GnduORJcRqbkTX3QYV2II7p1A3UfpDDaiNZbxB193gsaKh83tQLESI4o8dTtMqspGZTdEEfLQtk81Tnt-VV5lzqU_By_SPNnrHO4kx0rQdVN3B4W8GOK58WlQDHLq7LHsq9T1fQ6gdgZTpBb1L7BKALzbekeK7l9cagDRzM7v6BTutL5Fd6PPXaUKVtj_rqWBc25fc9Z3MMdOlgIOoq5OH_KwYM9aA0PGy_YkYUYQUumRkHKwoo5GkuBai0GfW8W9bqfHXOlDidBMvZiHfeq2oZNQ8OjDJLVxvoTYj1itATxu4wGgawtKnWiSC3PyKqxAJ_uyFVgg08o-maNoRYy36tL-woXSyJLFGyXwZV3oNMJ_hTh4gIPKHW5-WDjfhXYB2ifGXFqd2AePR-dbAeEEW-Dc1wOYtWzi1WzV6Va42fhni2sU=w1497-h887-no" /&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;通过这两张图可以看到，在GraphDB中设计模型比在RDBMS中设计模型要简单。&lt;/p&gt;</summary></entry><entry><title>图形数据库-1</title><link href="/tu-xing-shu-ju-ku-1.html" rel="alternate"></link><updated>2016-01-27T00:00:00+08:00</updated><author><name>andy.zhangtao</name></author><id>tag:,2016-01-27:tu-xing-shu-ju-ku-1.html</id><summary type="html">&lt;h1&gt;图形数据库(GraphDB)&lt;/h1&gt;
&lt;p&gt;&lt;br/&gt;
如果您对此文章感兴趣，欢迎发邮件至&lt;a href="&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#116;&amp;#111;&amp;#58;&amp;#97;&amp;#110;&amp;#100;&amp;#121;&amp;#46;&amp;#122;&amp;#104;&amp;#97;&amp;#110;&amp;#103;&amp;#116;&amp;#97;&amp;#111;&amp;#64;&amp;#104;&amp;#111;&amp;#116;&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#46;&amp;#99;&amp;#111;&amp;#109;"&gt;&amp;#97;&amp;#110;&amp;#100;&amp;#121;&amp;#46;&amp;#122;&amp;#104;&amp;#97;&amp;#110;&amp;#103;&amp;#116;&amp;#97;&amp;#111;&amp;#64;&amp;#104;&amp;#111;&amp;#116;&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#46;&amp;#99;&amp;#111;&amp;#109;&lt;/a&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;何谓图形数据库&lt;/h2&gt;
&lt;p&gt;&lt;br/&gt;
在我们生存的实际世界当中，到处都存在着"关系"。世界当中没有独立存在的事物，在我们身边充斥着大量的，相互交织的各种关系。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
如果需要处理这些相互交织的关系数据，凭借关系型数据库是无法完成的。此时，就需要一种以关系为核心，并且可以高效存储，高效处理的数据库。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
相对于图形数据库而言，关系型数据库虽然也可以计算这些"关系"数据，但计算的代价却是异常昂贵。得益于图形数据库天生以"关系"为核心，因此其在检索关系数据时非常高效，目前可以支持每颗CPU每秒处理百万次关系检索，效率比RDBMS高出好几个数量级。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
那图形数据库会替代RDBMS吗？首先来说，两者适用场景不同。图形数据库更加侧重于处理海量数据下的，高度链接的关系拓扑关系和复杂的查询需求，而这些恰恰不是RDBMS的强项。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
&lt;img alt="image" src="https://lh3.googleusercontent.com/s8jMKkYD6xAtGxvN57IAm2yQl-DXX7U_-7iZ3WC20UQXRQFAblm_hDZsRuuxkRmqYdis4ywTXSM--zBITBTbxatf3xpXaPAC_vs_pvkQIxybJpccpXuoTihLd8qNDNNNcV8hXYvUjWYPsJB5F1c12O2h-AEKpybswKAfAj7BDZwmquwq-Sqkrjb_YbvCLyv4LHa2l1olv4gnpDShws3TjNSQFbZPG_trsRxz25d0z47Mk6PRuI-C8O0M6T9sr7G6wgJ0qyFiU9D6RSIlEjPMUi_gtX4UWA7_EjEP0C5dHtjDGP_FsgVuylG83a5ISDWCuGOktxRaaC1XaJQus6ySdCxjXZAcQt1IbaCLTYju5EN5r6tUZR4pNL7KikOWlk8p1kYF9AbnZdQKdfIHMsPam3_eLPo9V5UA15I-rvEDFqEl66vAyusoRknl7qGjOA3wrw1Oro9Lv1aq9acsWaIVAo0p_JHSKAO8-8ui6FDplAu_MjssTlxqRn10HWwFOEpr9S5OdvFfH3i_7JhMH6PO-zNjuaipr0lYBOcCobHCkUeLhs6i8x2Sci8a7gh4sHVApRk=w283-h323-no" /&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;图形数据库使用的数据模型&lt;/h2&gt;
&lt;p&gt;&lt;br/&gt;
如果读者接触过对象模型或者实体图，那么想必对下面的模型必然不陌生。在图形数据库模型中，一个实体称之为一个节点(node)，每个node都有非常多的属性，这些属性通过key-value来表示。相同的node在不同的场景当中可以拥有不同的标签信息(lable)。而这些Lable信息，除了可以用来标记node之外，也可以用来附加一些metadata(例如索引信息或者约束信息等).&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
&lt;img alt="image" src="https://lh3.googleusercontent.com/YOI-JTUEhROm2H5tnjbuvd_eGuYcnNn1byjlsfu4UpkQZP1TJAkEZbUA_vgDEW_XiapmWFJe1IgLMiCLGit1W2EEJo_CoANCybOK78qGoI7zsT9QNKDtiOMLD1-VEp2irRJxsVGnvt6cGKG0uCc2rpK6njgJxeYUSoG5rLt2NWo1giNp4yXFPMR6FN8L9f2-63cx4WfbyQ7JkxX5Gb8YNMD0jXGKTe0FJtQsvwqlqcQKJ2xOYmZ7HfY-6DAZ8Q3O3aEneIbStOEK_-tB0Bjr86n3gfhGbiign49icpIuBRKC3GH6hrl4BJwjKfrSvfsS5dIA1RjbxJF19sf6c3j6h3zV62ragk_-Q21BSMjfeCA-NcHqaT-IBWNx_OfUAbd_Md2LcxI3wRTuEv9zFck_Ie4xZUqyx0-VUaUC8HGjzG8v1oG7ZR2ufz982s9S4GcDffVmMyvRaRSB2H0MemWrd55DzjZ-wQNJUaiT2hdHOtPzXCMh_LgWGBruVgAJXbFic0fIRA-QC-kqg1IhtNwKJeoduEEE-thnlFKi_oi0AymGiqVp-op6EDl9HKhIFiizjQk=w730-h475-no" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
而在两个节点之间，有向并且语义清楚的连接就称之为关系。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
通常来说，一个关系包括方向，类型，起点node和结束node四个要素。而对于node来说，一个关系则可以同时拥有多个属性。例如权重，代价，距离，级别，新鲜度或者优势度等等。因为在图形数据库当中，维护一条关系是一个代价非常小的事情，所以两个节点之间可以在不带来额外性能损失的情况下，拥有无限条的关系或者属性。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
但有一点需要注意，尽管关系是有向的，但关系本身却不关心方向。只有node才会关心方向。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
虽然关系很便宜，但在图形数据库当中却有一条铁的纪律:"不允许存在死链"。因为每条关系都必须存在起始node和结束node，所以用户无法在删除所有关系之前删除掉与之相关联的node。用户可以认为，一条存在的关系必然会连接两个存在的node。&lt;/p&gt;</summary></entry><entry><title>如何跨平台编译Golang</title><link href="/ru-he-kua-ping-tai-bian-yi-golang.html" rel="alternate"></link><updated>2016-01-19T00:00:00+08:00</updated><author><name>andy.zhangtao</name></author><id>tag:,2016-01-19:ru-he-kua-ping-tai-bian-yi-golang.html</id><summary type="html">&lt;h1&gt;如何跨平台编译Golang程序&lt;/h1&gt;
&lt;p&gt;跨平台编译Golang程序的方法有很多种，下面仅介绍基于Docker的编译方式。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
&lt;strong&gt;我们假设当前golang版本为1.4&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;build&lt;/h2&gt;
&lt;p&gt;需要Pull的image如下：&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;golang:1.4&lt;/li&gt;
&lt;li&gt;golang:1.4.3-cross&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;为什么需要两个image呢？这是golang:1.4.3-cross经常出现pull failed的情况，可能是人品问题吧.... 所以我们需要基于golang:1.4来build golang:1.4.3-cross。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;下面是build golang：1.4.3-cross所使用的Dockerfile：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;FROM golang:1.4

ENV GOLANG_CROSSPLATFORMS \
    darwin/386 darwin/amd64 \
    dragonfly/386 dragonfly/amd64 \
    freebsd/386 freebsd/amd64 freebsd/arm \
    linux/386 linux/amd64 linux/arm \
    nacl/386 nacl/amd64p32 nacl/arm \
    netbsd/386 netbsd/amd64 netbsd/arm \
    openbsd/386 openbsd/amd64 \
    plan9/386 plan9/amd64 \
    solaris/amd64 \
    windows/386 windows/amd64

ENV GOARM 5

RUN cd /usr/src/go/src \
    &lt;span class="err"&gt;&amp;amp;&amp;amp;&lt;/span&gt; set -ex \
    &lt;span class="err"&gt;&amp;amp;&amp;amp;&lt;/span&gt; for platform in &lt;span class="nv"&gt;$GOLANG_CROSSPLATFORMS&lt;/span&gt;; do \
        GOOS=&lt;span class="cp"&gt;${&lt;/span&gt;&lt;span class="n"&gt;platform&lt;/span&gt;&lt;span class="o"&gt;%/*&lt;/span&gt;&lt;span class="cp"&gt;}&lt;/span&gt; \
        GOARCH=&lt;span class="cp"&gt;${&lt;/span&gt;&lt;span class="n"&gt;platform&lt;/span&gt;&lt;span class="c"&gt;##*/&lt;/span&gt;&lt;span class="cp"&gt;}&lt;/span&gt; \
        ./make.bash --no-clean 2&amp;gt;&lt;span class="ni"&gt;&amp;amp;1;&lt;/span&gt; \
    done
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;通过执行docker build -t golang:1.4.3-cross . 就可以build出一个可用的cross image。
&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;如何使用&lt;/h2&gt;
&lt;p&gt;我们假设目前有已经写好的golang程序，目录名为：mygolang。那么执行下面的语句将mygolang的源码挂载到image中：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;docker run --rm -it -v &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;PWD&lt;/span&gt;&lt;span class="x"&gt;&amp;quot;:/usr/src/myapp -w /usr/src/myapp golang:1.4.3-cross bash&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;然后在新创建的bash中，执行：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; GOOS in darwin linux windows&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
&amp;gt;   &lt;span class="k"&gt;for&lt;/span&gt; GOARCH in &lt;span class="m"&gt;386&lt;/span&gt; amd64&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
&amp;gt;     go build -v -o myapp-&lt;span class="nv"&gt;$GOOS&lt;/span&gt;-&lt;span class="nv"&gt;$GOARCH&lt;/span&gt;
&amp;gt;   &lt;span class="k"&gt;done&lt;/span&gt;
&amp;gt; &lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br/&gt;
这样就可以编译出三种平台32/64位共6个可执行程序。
&lt;br/&gt;
也可以通过下面方式只编译特定平台：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;docker run --rm -v &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$PWD&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;:/usr/src/myapp -w /usr/src/myapp -e &lt;span class="nv"&gt;GOOS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;windows -e &lt;span class="nv"&gt;GOARCH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;386&lt;/span&gt; golang:1.4.3-cross go build -v
&lt;/pre&gt;&lt;/div&gt;</summary></entry><entry><title>Linux常用命令</title><link href="/linuxchang-yong-ming-ling.html" rel="alternate"></link><updated>2016-01-14T00:00:00+08:00</updated><author><name>andy.zhangtao</name></author><id>tag:,2016-01-14:linuxchang-yong-ming-ling.html</id><summary type="html">&lt;h1&gt;Linux常用命令(TBD)&lt;/h1&gt;
&lt;h2&gt;删除邮件&lt;/h2&gt;
&lt;p&gt;&lt;br/&gt;
每次登录时都会显示"you have new mail"，挺烦人的。 执行下面的命令删除掉所有邮件:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;mail
? delete *
? q
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;LFTP下载文件&lt;/h2&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h3&gt;多线程下载&lt;/h3&gt;
&lt;p&gt;lftp -c "pget -n &amp;lt;线程数量&amp;gt; 文件路径"
&lt;br/&gt;&lt;/p&gt;
&lt;h3&gt;多线程下载＋文件重命名&lt;/h3&gt;
&lt;p&gt;lftp -c "pget -n &amp;lt;线程数量&amp;gt; 文件路径 －o 本地文件名"&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;Sed修改文件&lt;/h2&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h3&gt;删除一行&lt;/h3&gt;
&lt;p&gt;sed -i "2d"  &lt;file path&gt; #删除第二行
&lt;br/&gt;&lt;/p&gt;
&lt;h3&gt;获取行号&lt;/h3&gt;
&lt;p&gt;sed -n -e "/&amp;lt;匹配字符串&amp;gt;/="  &lt;file path&gt; #获取匹配字符串所在行号
&lt;br/&gt;&lt;/p&gt;
&lt;h3&gt;使用变量&lt;/h3&gt;
&lt;p&gt;sed -i "s/${OLDBUILD}/${MYBUILD}/" ${PWD}/${FILEPATH} #使用&lt;strong&gt;""&lt;/strong&gt;才可以引入变量
&lt;br/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;&amp;amp;和&amp;amp;&amp;amp;的区别&lt;/h2&gt;
&lt;p&gt;&amp;amp;表示当前命令作为后台进程执行，不阻塞后面命令的执行。
而&amp;amp;&amp;amp;表示只有当前面命令执行成功后才能执行后面的命令，而||则相反，只有前面命令失败之后才会执行后面的命令。
&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;使用case的例子&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;case &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;TYPE&lt;/span&gt;&lt;span class="x"&gt;&amp;quot; in&lt;/span&gt;
&lt;span class="x"&gt;    all )&lt;/span&gt;
&lt;span class="x"&gt;        command&lt;/span&gt;
&lt;span class="x"&gt;        ;;&lt;/span&gt;
&lt;span class="x"&gt;    build )&lt;/span&gt;
&lt;span class="x"&gt;        command&lt;/span&gt;
&lt;span class="x"&gt;        ;;&lt;/span&gt;
&lt;span class="x"&gt;    replace )&lt;/span&gt;
&lt;span class="x"&gt;        command&lt;/span&gt;
&lt;span class="x"&gt;        ;;&lt;/span&gt;
&lt;span class="x"&gt;    runuat )&lt;/span&gt;
&lt;span class="x"&gt;        command&lt;/span&gt;
&lt;span class="x"&gt;        ;;&lt;/span&gt;
&lt;span class="x"&gt;esac&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;判断参数是否为空的例子&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;TYPE=&amp;quot;&lt;span class="cp"&gt;${&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="cp"&gt;}&lt;/span&gt;&amp;quot;

t_usage()
{
    echo
    echo &amp;quot;Usage: {Type} {Projectname}&amp;quot;
    exit -1
} # t_usage

if [ -z &amp;quot;&lt;span class="cp"&gt;${&lt;/span&gt;&lt;span class="n"&gt;TYPE&lt;/span&gt;&lt;span class="cp"&gt;}&lt;/span&gt;&amp;quot; ] ; then
    t_usage
fi
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;使用for循环的例子&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;WEB_BUILD[0]=&amp;quot;command&amp;quot;
WEB_BUILD[1]=&amp;quot;command&amp;quot;
WEB_BUILD[2]=&amp;quot;command &amp;quot; 

for i in &amp;quot;&lt;span class="cp"&gt;${&lt;/span&gt;&lt;span class="err"&gt;!&lt;/span&gt;&lt;span class="n"&gt;WEB_BUILD&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="cp"&gt;}&lt;/span&gt;&amp;quot;; do 
    bash -c &amp;quot;&lt;span class="cp"&gt;${&lt;/span&gt;&lt;span class="n"&gt;WEB_BUILD&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="cp"&gt;}&lt;/span&gt;&amp;quot; &amp;gt;&amp;gt; /tmp/build.log 
done
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;通过ftp下载多个文件时关闭提示&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;ftp&amp;gt; prompt
ftp&amp;gt; mget *
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;通过Lftp镜像远程目录&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;lftp -e &amp;quot;mirror -P &amp;lt;并行下载文件个数&amp;gt; &amp;quot; &amp;lt;FTP/SFTP IP/Hostname&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;Linux常见压缩文件的解压&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;1、*.tar 用 tar –xvf 解压
2、*.gz 用 gzip -d或者gunzip 解压
3、*.tar.gz和*.tgz 用 tar –xzf 解压
4、*.bz2 用 bzip2 -d或者用bunzip2 解压
5、*.tar.bz2用tar –xjf 解压
6、*.Z 用 uncompress 解压
7、*.tar.Z 用tar –xZf 解压
8、*.rar 用 unrar e解压
9、*.zip 用 unzip 解压
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;使用GREP显示行号&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;grep -n &amp;lt;data&amp;gt; FILENAME
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;br/&gt;&lt;/p&gt;</summary></entry><entry><title>升级Docker 1.10遇到的小问题</title><link href="/sheng-ji-docker-110yu-dao-de-xiao-wen-ti.html" rel="alternate"></link><updated>2016-01-13T00:00:00+08:00</updated><author><name>andy.zhangtao</name></author><id>tag:,2016-01-13:sheng-ji-docker-110yu-dao-de-xiao-wen-ti.html</id><summary type="html">&lt;h1&gt;Docker升级到1.10遇到的小问题&lt;/h1&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;目前Docker最新开发版本为1.10，在1.10当中，Docker从内核层面做了很多重构。将以前偶合度较高的代码通过Interface进行了接耦合，代码逻辑关系变的非常清晰。
&lt;br/&gt;
在1.10版本中，docker主要改进了以下几个方面：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;支持使用plugin。(有了这个功能以后，估计开放docker插件的人就会非常多了)&lt;/li&gt;
&lt;li&gt;增强namespaces稳定性。&lt;/li&gt;
&lt;li&gt;重新编排了Remote API。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果用户想要尝鲜试用1.10，那么最简单的方式就是从github上面clone docker sourcecode，然后build。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;当启动docker 1.10之后，docker需要迁移旧版本的数据。 而本人恰恰在这个环节遇到了诡异的问题。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;起因&lt;/h2&gt;
&lt;p&gt;首先我来描述一下问题发生的步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;关闭旧版本的docker。 我没有通过service docker stop的方式停止，而是直接通过kill docker process的方式。(事后证明，这种方式相当错误)&lt;/li&gt;
&lt;li&gt;将旧版本的docker替换为docker 1.10。 &lt;/li&gt;
&lt;li&gt;正常启动docker 1.10. (如果是第一次启动，建议输出debug信息，方便失败后分析原因)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;然后问题就出现了，Docker daemon提示：xxxxxx container中的config.json不存在，daemon初始化失败。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;经过&lt;/h2&gt;
&lt;p&gt;按照以前使用docker的经验来看，是container的配置文件出了问题。因此，我首先判断以下方面是否正常：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;contaienr路径是否正常。(也就是验证一下这个路径是否存在，权限是否正确)&lt;/li&gt;
&lt;li&gt;daemon所读取的文件是否正常.(验证文件是否存在，文件内容是否正确，文件权限是否正确)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在验证第二条时发现，这个container目录虽然存在，但只是一个空目录，没有任何文件。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
再启动docker 1.9，发现一切正常。继续分析日志可以发现，这个错误是在docker 1.10执行migrate时报出的。那么也就是docker1.10需要将旧container数据结构转化为新的数据结构，在转换时发现config.json为空，因此报错退出。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;那么，目前需要明确：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;migrate是否是必须的步骤?&lt;/li&gt;
&lt;li&gt;migrate时是否每个container都要成功?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;从docker1.10的角度分析，新内核采取了新的数据结构，旧数据结构很可能支持度有限，那么迁移一定是需要做的。但是否每个container都需要迁移成功呢？
&lt;br/&gt;
正常情况下，每个contianer在创建时都会生成一系列的配置文件。如果某个container出现丢失配置文件的情况，那么只可能发生在create container时出现了异常，说的直白点就是：create container过程中，强行关闭了docker daemon，导致配置文件没有生成。(也就是上面所提到的强行kill的结果)&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
在这种情况下，因为这个container实际上没有对外提供任何服务，所以也可以认为这个container是可删的。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
那么就明确了，在迁移时不需要保证每个container都迁移成功。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
但这个问题应该如何处理呢？&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;结果&lt;/h2&gt;
&lt;p&gt;解决方案有两套：&lt;/p&gt;
&lt;p&gt;方案1.    删除空目录，也就是在container目录中删除那个创建失败的container。为什么这么做呢？因为分析完代码后发现，迁移代码就是遍历container目录，然后逐个container进行迁移。因此删除掉就恢复正常。&lt;/p&gt;
&lt;p&gt;方案2.    修改代码，当发现container迁移失败时，跳过此container，继续后面的工作。不能阻塞daemon初始化。这个方案是治根的方案。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
方案1最简单，而方案2最稳妥。 目前我已经fix了这个defect，docker已经将这部分fix代码merge到了1.10版本中。重新clone 1.10的代码，然后重新build就可以彻底解决这个问题。&lt;/p&gt;</summary></entry><entry><title>如何在Mac上面搭建Docker开发环境</title><link href="/ru-he-zai-macshang-mian-da-jian-dockerkai-fa-huan-jing.html" rel="alternate"></link><updated>2016-01-06T15:03:00+08:00</updated><author><name>andy.zhangtao</name></author><id>tag:,2016-01-06:ru-he-zai-macshang-mian-da-jian-dockerkai-fa-huan-jing.html</id><summary type="html">&lt;h1&gt;如何在Mac上面搭建Docker开发环境&lt;/h1&gt;
&lt;p&gt;按照欧美技术范儿来说，开发机器十有八九都是Mac。Docker开发应该也是在Mac上面进行的，所以一开始认为直接从git上面clone docker src，然后执行make应该就大功告成。但中间还是遇到了一些挫折，所以我把过程提供出来以供以后查询备用。&lt;/p&gt;
&lt;h3&gt;从git上面clone是第一步&lt;/h3&gt;
&lt;p&gt;首先需要从git上面clone Docker source code。 Git地址是：https://github.com/docker/docker.git。
这一步就是耗费时间，只要网络不断应该就没有问题。&lt;/p&gt;
&lt;h3&gt;在本地Mac上面安装Docker&lt;/h3&gt;
&lt;p&gt;这一步后面命令执行成功的前提。因为后面所有的步骤都是基于Docker Image执行的。所以本地一定要有Docker运行环境。因为Docker目前还不支持在原生Mac os上面执行，所以想要借助于Virtualbox来实现。 具体安装步骤可参考&lt;a href="https://docs.docker.com/engine/installation/mac/"&gt;&amp;lt;如何在Mac上面运行Docker&amp;gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;检测storage.googleapis.com是否可访问&lt;/h3&gt;
&lt;p&gt;Docker需要从storage.googleapis.com这里下载go的最新版本。但这个域名处于BFW监控之中，所以在大陆境内很有可能无法访问。当前此域名对应IP是216.58.197.112。 所以我的处理方法是修改Dockerfile，直接修改hosts文件。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;RUN echo 216.58.197.112  storage.googleapis.com &amp;gt;&amp;gt; /etc/hosts;curl -sSL  &amp;quot;https://storage.googleapis.com/golang/go&lt;span class="cp"&gt;${&lt;/span&gt;&lt;span class="n"&gt;GO_VERSION&lt;/span&gt;&lt;span class="cp"&gt;}&lt;/span&gt;.linux-amd64.tar.gz&amp;quot; | tar -v -C /usr/local -xz
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;执行Makefile&lt;/h3&gt;
&lt;p&gt;到这里，就可以通过make命令来执行Makfile了。 如果是在大陆境内，这一步非常耗时。但理论上来说应该是不会报错的。所以干点别的去吧，大概在1个小时之后再回来看看结果。&lt;/p&gt;
&lt;h3&gt;设定BINDDIR&lt;/h3&gt;
&lt;p&gt;即便上面那一步执行成功了，你也无法看到Docker可执行程序。这是因为下面的语句所造成的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;BIND_DIR&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;BINDDIR&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;BINDDIR&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;DOCKER_HOST&lt;span class="k"&gt;)&lt;/span&gt;,,bundles&lt;span class="k"&gt;))&lt;/span&gt;
&lt;span class="nv"&gt;DOCKER_MOUNT&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;BIND_DIR&lt;span class="k"&gt;)&lt;/span&gt;,-v &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;CURDIR&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;BIND_DIR&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;:/go/src/github.com/docker/docker/&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;BIND_DIR&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;BIND_DIR是编译后的目标目录。如果BINDDIR没有设置，那么就会通过$(if $(DOCKER_HOST),,bundles)来判断。&lt;/p&gt;
&lt;p&gt;$(if $(DOCKER_HOST),,bundles)的意思是如果DOCKER_HOST有值，那么就返回空，如果没有值就返回bundles。&lt;/p&gt;
&lt;p&gt;问题就出在这里，因为当前环境是Mac OS。而为了可以执行此Makefile脚本，就需要在Mac中运行Docker。如此一来，就一定会出现DOCKER_HOST变量。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;echo &lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;DOCKER_HOST&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;tcp://192.168.99.100:2376&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这样BIND_DIR就为空。因此就不会挂载任何目录到编译Container之中，所以即便编译成功了，也不会输出任何可执行程序。&lt;/p&gt;
&lt;p&gt;解决方案有三个：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;设定BINDDIR。 BINDDIR := bundles&lt;/li&gt;
&lt;li&gt;当DOCKER_HOST有值时返回bundles。 if $(DOCKER_HOST),bundles,&lt;/li&gt;
&lt;li&gt;在make中设定值。make BIND_DIR=bundles&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;然后再执行make，就可以在bundles目录中看到最终的可执行程序了。&lt;/p&gt;</summary></entry><entry><title>Docker输出日志的几种方式</title><link href="/dockershu-chu-ri-zhi-de-ji-chong-fang-shi.html" rel="alternate"></link><updated>2016-01-04T21:51:00+08:00</updated><author><name>andy.zhangtao</name></author><id>tag:,2016-01-04:dockershu-chu-ri-zhi-de-ji-chong-fang-shi.html</id><summary type="html">&lt;h1&gt;Docker输出日志的几种方式&lt;/h1&gt;
&lt;p&gt;在使用Docker过程中，查看日志是必不可少的一项工作。通过Docker提供的docker logs命令可以查看指定容器所输出的日志。但此命令有一些限制范围，当前docker logs命令仅仅只能支持json-file,journald这两种日志驱动，如果container使用其它类型的日志驱动，那么logs命令将无法提取日志。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;那么如何查看容器所输出的日志呢？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了解决这个问题，我们首先来看看Docker都支持哪些类型的日志驱动。&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Docker支持的日志驱动类型&lt;/h2&gt;
&lt;p&gt;Docker目前支持以下类型的驱动：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;驱动名称&lt;/th&gt;
&lt;th&gt;是否支持logs&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;json-file&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;journald&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;syslog&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;gelf&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;fluentd&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;awslogs&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;Docker如何指定日志驱动？&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;指定日志驱动有两种方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过Daemon指定全局默认日志驱动&lt;/li&gt;
&lt;li&gt;通过Run命令指定特定日志驱动&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果需要指定全局默认日志驱动，可以在启动Docker Daemon时指定，命令如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;docker daemon --log-driver=json-file --log-opt labels=foo --log-opt env=foo,fizz
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;当执行完这条命令之后，以后所有新创建的Container都默认使用json-file来保存日志。这就是全局默认模式。如果需要给特定的Container指定日志驱动，那么就可以参考下面的命令：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;docker run --log-driver&lt;span class="o"&gt;=&lt;/span&gt;syslog --log-opt syslog-address&lt;span class="o"&gt;=&lt;/span&gt;tcp://192.168.0.42:123 ubuntu
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;各个日志驱动的用法&lt;/h2&gt;
&lt;hr /&gt;
&lt;h3&gt;Json-file 驱动&lt;/h3&gt;
&lt;p&gt;Json-file驱动有四个配置参数(以下参数均通过--log-opt设置)：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;参数名称&lt;/th&gt;
&lt;th&gt;参数说明&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;max-size&lt;/td&gt;
&lt;td&gt;[0-9+][k\&lt;/td&gt;
&lt;td&gt;m\&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max-file&lt;/td&gt;
&lt;td&gt;[0-9+]&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;labels&lt;/td&gt;
&lt;td&gt;label1,label2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;env&lt;/td&gt;
&lt;td&gt;env1,env2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;max-size用于设置日志文件大小，单位为k，m和g。例如--log-opt max-size＝50m，可以将日志文件设置为50mb。当日志文件超过50mb之后，Docker将会重新生成新日志文件。如果max-size没有设置，那么Docker将永远不会生成新日志文件。&lt;/p&gt;
&lt;p&gt;max-file用于设置日志文件数量。例如--log-opt max-file=100。Docker将只会保存最后100个日志文件。如果max-file没有设置，那么Docker将会保存所有的日志文件。&lt;/p&gt;
&lt;p&gt;labels和env用于设置日志标签。&lt;/p&gt;
&lt;h3&gt;syslog 驱动&lt;/h3&gt;
&lt;p&gt;Docker可以将日志发送到syslog服务器(因为syslog服务器兼容rsyslog服务器，所以Docker也可将日志分送至rsyslog server)。&lt;/p&gt;
&lt;p&gt;syslog可使用的参数如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;--log-opt syslog-address=[tcp|udp]://host:port
--log-opt syslog-address=unix://path
--log-opt syslog-facility=daemon
--log-opt tag=&amp;quot;mailer&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;syslog-address用来设置syslog(rsyslogd)server的IP和端口。 syslog-facility用来设置发送设备名称，目前可以设置的设备名称如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kern&lt;/li&gt;
&lt;li&gt;user&lt;/li&gt;
&lt;li&gt;mail&lt;/li&gt;
&lt;li&gt;daemon&lt;/li&gt;
&lt;li&gt;auth&lt;/li&gt;
&lt;li&gt;syslog&lt;/li&gt;
&lt;li&gt;lpr&lt;/li&gt;
&lt;li&gt;news&lt;/li&gt;
&lt;li&gt;uucp&lt;/li&gt;
&lt;li&gt;cron&lt;/li&gt;
&lt;li&gt;authpriv&lt;/li&gt;
&lt;li&gt;ftp&lt;/li&gt;
&lt;li&gt;local0&lt;/li&gt;
&lt;li&gt;local1&lt;/li&gt;
&lt;li&gt;local2&lt;/li&gt;
&lt;li&gt;local3&lt;/li&gt;
&lt;li&gt;local4&lt;/li&gt;
&lt;li&gt;local5&lt;/li&gt;
&lt;li&gt;local6&lt;/li&gt;
&lt;li&gt;local7&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;默认情况下，Docker使用Container short name作为日志标记名称，但用户也可以通过tag来重命名此名称。&lt;/p&gt;
&lt;h3&gt;journald 驱动&lt;/h3&gt;
&lt;p&gt;如果用户指定了journald驱动，Docker将会把所有日志发送到Docker.service日志中(默认情况)。用户可以通过journalctl 来筛选日志。&lt;/p&gt;
&lt;h3&gt;gelf 驱动&lt;/h3&gt;
&lt;p&gt;gelf驱动的使用方式和syslog的使用方式类似，可搭配的参数如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;--log-opt gelf-address=udp://host:port
--log-opt tag=&amp;quot;database&amp;quot;
--log-opt labels=label1,label2
--log-opt env=env1,env2
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;fluentd 驱动&lt;/h3&gt;
&lt;p&gt;在使用fluentd驱动时需要注意一点，如果用户所指定的fluentd服务器地址不可达，那么此容器将会报错退出。而其它驱动则不会出现这种情况。&lt;/p&gt;
&lt;p&gt;使用fluentd驱动的命令如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;docker run --log-driver=fluentd --log-opt fluentd-address=localhost:24224 --log-opt tag=docker.&lt;/span&gt;&lt;span class="cp"&gt;{{&lt;/span&gt;&lt;span class="nv"&gt;.Name&lt;/span&gt;&lt;span class="cp"&gt;}}&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;aws logs驱动&lt;/h3&gt;
&lt;p&gt;AWS驱动使用目前不太普遍，所以下面仅提供使用参数：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;--log-opt awslogs-region=&amp;lt;aws_region&amp;gt;
--log-opt awslogs-group=&amp;lt;log_group_name&amp;gt;
--log-opt awslogs-stream=&amp;lt;log_stream_name&amp;gt;
&lt;/pre&gt;&lt;/div&gt;</summary></entry><entry><title>Docker 如何管理Image,Container</title><link href="/docker-ru-he-guan-li-imagecontainer.html" rel="alternate"></link><updated>2016-01-04T00:00:00+08:00</updated><author><name>andy.zhangtao</name></author><id>tag:,2016-01-04:docker-ru-he-guan-li-imagecontainer.html</id><summary type="html">&lt;h1&gt;Docker 如何管理Image,Container？&lt;/h1&gt;
&lt;p&gt;在使用Docker之前，有一个问题始终无法回避：Docker如何高效的管理和使用Image和Container数据？
为了搞明白这个问题，我们首先需要理解：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Docker如何构建和存储Image？&lt;/li&gt;
&lt;li&gt;Docker如何基于Image来创建Container？&lt;/li&gt;
&lt;li&gt;Docker如何操作Image和Container？&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Image和Container的基础 － Layers(文件层)&lt;/h2&gt;
&lt;p&gt;从数据结构上面来看，Docker当中所有的Image都是一系列&lt;strong&gt;有序&lt;/strong&gt;只读(Read-Only)文件层(Layers)的集合。位于这个集合最顶端的文件层，我们称之为BaseImage。其它文件层都依赖于它。下图是一个Ubuntu15.04的Image示意图，这个Image包含了4个文件层。
&lt;img alt="image" src="https://lh3.googleusercontent.com/-D8MQPkSpeb8/VonUe0SEWKI/AAAAAAAAAAw/NXLg19gDpq4/s448-Ic42/image-layers.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;当用户在这个Container中做任何写操作时，例如：在/tmp目录中新创建一个文件，Docker就会在这个集合最下面再创建一个文件层来保存这种变化。Docker当中每个文件层都有一个唯一ID(UUID)，并且每个文件层都会记录其所依赖的文件层信息。&lt;/p&gt;
&lt;p&gt;Image都是由Layers组成的，与此相对应的，所有的Container也同样是由Layers组成的。但Container与Image又一个本质区别，组成Image的Layer都是RO，而组成Container的Layer中，处于最低端的Layer是RW，其它Layer都是RO。这个RW的Layer，我们称之为Thin R/W Layer。如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="https://lh3.googleusercontent.com/-z4JVQrV79zw/VonUe_iczQI/AAAAAAAAABE/KIr8ecUp4pM/s675-Ic42/container-layers.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Image和Container本质的区别就在于这个R/W Layer。在Container当中所发生的所有写操作，都会被如实的纪录在此Layer之中。当Container被删除之后，这个Layer也会被随之删除。而Container所依赖的Image Layer集合则不会被删除。因此，Container可以理解为：&lt;strong&gt;Container=Image＋RW Layer&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;而正因为每个Container都有一个唯一的RW Layer，这就意味着多个Container可以共享同一份Image，并且可以保存其各自数据。下图显示多个Container如何共享同一份Image。
&lt;img alt="image" src="https://lh3.googleusercontent.com/-QyW-QTY2if4/VonUgIVxhcI/AAAAAAAAABM/CCQeIem92IE/s769-Ic42/sharing-layers.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Docker通过两种技术来高效的使用Image和Container，一是：Layer依赖，二是：写时复制(Copy-on-Write)。本节当中，我们介绍的是Layer依赖。下节我们将会介绍写时复制。&lt;/p&gt;
&lt;h2&gt;写时复制(Copy-on-Write)&lt;/h2&gt;
&lt;p&gt;通过资源共享可以很好的利用当前资源。这种方式不仅仅发生在数字世界当中，在人类实际情况中也经常发生。&lt;/p&gt;
&lt;p&gt;例如：我们假设目前有一对双胞胎，阿猫和阿狗(权当他俩是双胞胎)。两个双胞胎在不同的班级上学，某一天两人的老师分别留了相同的作业。阿猫很快的写完了作业，而阿狗则贪玩没有写。第二天需要交作业时，因为是同一个老师上课，而俩人又不在同一个班级，因此交作业的时间就可以错开。阿猫先交作业，老师审核没问题，作业就还给了阿猫(我们假设老师没有做任何批改)。然后阿猫在下课时将作业给了阿狗，那么阿狗就可以使用同一份作业来糊弄老师。如此一来，两个人只写了一份作业，就通过了两次审核，为国家绿色环保做了贡献。&lt;/p&gt;
&lt;p&gt;写时复制就是上面过程的数字化。在写时复制策略中，需要数据的进程仅仅只需要使用目前已经存在的数据就可以，而不是在重新拷贝复制一份。只有这个进程需要修改数据了，才会单独拷贝一份，除此之外完全不需要单独保存数据。&lt;/p&gt;
&lt;p&gt;Docker通过COW策略来管理Image和Container数据。通过COW策略，Docker可以更高效的利用磁盘空间和网络带宽资源。下一节，我们来看看COW策略是如何在Docker中应用的。&lt;/p&gt;
&lt;h2&gt;COW在Docker中的应用&lt;/h2&gt;
&lt;p&gt;本节，我们聚焦于Docker如何通过COW策略来管理Image和Container。首先，我们引入两个命令:pull和push。 通过Docker pull命令，我们可以从远程仓库获取一个Image。例如下图所示：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;docker pull ubuntu:15.04
15.04: Pulling from library/ubuntu
6e6a100fa147: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
13c0c663a321: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
2bd276ed39d5: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
013f3d01d247: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
Digest: sha256:c7ecf33cef00ae34b131605c31486c91f5fd9a76315d075db2afd39d1ccdf3ed
Status: Downloaded newer image &lt;span class="k"&gt;for&lt;/span&gt; ubuntu:15.04
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;通过命令输出可以看到，Ubuntu15.04包含有四个Layer。这四个Layer组合起来才是一个完整的Ubuntu15.04 Image。所有的Image数据都是保存在本地，默认情况下是在/var/lib/docker目录之中。取决于不同的存储驱动，数据保存在docker目录中不同的子目录之中。&lt;/p&gt;
&lt;p&gt;如果我们假设目前使用的是AUFS存储驱动，那么可以通过下面的命令来查看下载到的Layer数据：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;sudo ls /var/lib/docker/aufs/layers
013f3d01d24738964bb7101fa83a926181d600ebecca7206dced59669e6e6778  2bd276ed39d5fcfd3d00ce0a190beeea508332f5aec3c6a125cc619a3fdbade6
13c0c663a321cd83a97f4ce1ecbaf17c2ba166527c3b06daaefe30695c5fcb8c  6e6a100fa147e6db53b684c8516e3e2588b160fd4898b6265545d5d4edb6796d
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;如果用户再下载另外一个基于Ubuntu15.04的Image，那么Docker就只会下载当前本地目录中没有的Layer数据，已经下载的这4个Layer则不会重复下载。&lt;/p&gt;
&lt;p&gt;我们可以通过下面的实例来演示这个过程。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先通过创建一个Dockerfile来引入Ubuntu15.04&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;FROM ubuntu:15.04
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;我们在新Image中的创建一个文件，并且写入Hello World。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;FROM ubuntu:15.04

RUN echo &amp;quot;Hello world&amp;quot; &amp;gt; /tmp/newfile
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;保存Dockerfile。然后开始构建新Image：&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    $ docker build -t changed-ubuntu .
    Sending build context to Docker daemon 2.048 kB
    Step 0 : FROM ubuntu:15.04
    ---&amp;gt; 013f3d01d247
    Step 1 : RUN echo &amp;quot;Hello world&amp;quot; &amp;gt; /tmp/newfile
    ---&amp;gt; Running in 2023460815df
    ---&amp;gt; 03b964f68d06
    Removing intermediate container 2023460815df
    Successfully built 03b964f68d06
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;通过Docker image命令，我们可以查看到构建成功的Image：&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE

changed-ubuntu      latest              03b964f68d06        33 seconds ago      131.4 MB  
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;通过Docker history命令来查看当前Image所包含的Layer集合。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    $ docker history changed-ubuntu
    IMAGE               CREATED              CREATED BY                                    SIZE           COMMENT
    03b964f68d06        About a minute ago   /bin/sh -c echo &amp;quot;Hello world&amp;quot; &amp;gt; /tmp/newfile    12 B                
    013f3d01d247        6 weeks ago          /bin/sh -c #(nop) CMD [&amp;quot;/bin/bash&amp;quot;]             0 B                 
    2bd276ed39d5        6 weeks ago          /bin/sh -c sed -i &amp;#39;s/^#\s*\(deb.*universe\)$/   1.879 kB            
    13c0c663a321        6 weeks ago          /bin/sh -c echo &amp;#39;#!/bin/sh&amp;#39; &amp;gt; /usr/sbin/polic   701 B               
    6e6a100fa147        6 weeks ago          /bin/sh -c #(nop) ADD file:49710b44e2ae0edef4   131.4 MB            
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;通过Docker history命令可以看到目前处于Layer集合最底层的Layer(03b964f68d06)就是我们通过"echo "Hello world" &amp;gt; /tmp/newfile"所创建的。 而其它四个Layer则是Ubuntu15.04所包含的4个Layer。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们通过查看目录来验证是否又单独拷贝了另外4个Layer。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    $ sudo ls /var/lib/docker/aufs/layers
    013f3d01d24738964bb7101fa83a926181d600ebecca7206dced59669e6e6778    2bd276ed39d5fcfd3d00ce0a190beeea508332f5aec3c6a125cc619a3fdbade6
    03b964f68d06a373933bd6d61d37610a34a355c168b08dfc604f57b20647e073    6e6a100fa147e6db53b684c8516e3e2588b160fd4898b6265545d5d4edb6796d
    13c0c663a321cd83a97f4ce1ecbaf17c2ba166527c3b06daaefe30695c5fcb8c
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;通过检查实际目录数据可以看到，当前文件系统中只有5个目录。因此，也就说明了，通过刚才的操作，虽然创建了一个新Image，但Docker并未完全拷贝所有Layer，而仅仅是创建了一个Layer。这个过程可以用下图来表示：&lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="https://lh3.googleusercontent.com/-I3jpGPoQeYM/VonUfB8x7iI/AAAAAAAAAA0/qx5XSS9nTrw/s757-Ic42/saving-space.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;通过COW策略，Docker可以高效利用磁盘空间，避免重复保存多余数据。&lt;/p&gt;
&lt;h2&gt;通过COW策略可以高效使用Container&lt;/h2&gt;
&lt;p&gt;我们在前面提到过，每一个Container最底层都有一个Thin R/W Layer。&lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="https://lh3.googleusercontent.com/-z4JVQrV79zw/VonUe_iczQI/AAAAAAAAABE/KIr8ecUp4pM/s675-Ic42/container-layers.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Container当中所有的写操作都被保存在这个Layer之中，而其它RO Layer则无法被修改。通过这种策略，多个Container可以共享使用同一份Layer集合。下图演示同时基于Ubuntu15.04创建多个Container，每个Container都有各自的RW Layer。&lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="https://lh3.googleusercontent.com/-QyW-QTY2if4/VonUgIVxhcI/AAAAAAAAABM/CCQeIem92IE/s769-Ic42/sharing-layers.jpg" /&gt;       &lt;/p&gt;
&lt;p&gt;当容器当中发生写操作时，Docker会触发一个COW操作。具体的COW处理则依赖于具体的存储驱动，AUFS和BTFS的处理方式就各不相同。&lt;/p&gt;
&lt;p&gt;如果容器需要保存大量数据，那么Docker推荐将这些数据通过data volume来保存，而不建议直接将这些数据写入RW Layer。因为通过COW操作来保存数据时，会出现明显的性能下降。而下降的程度则取决于当前Docker所使用的存储驱动方式。通常来说，保存大文件，保存多个Layer和保存多层级的目录树都会引起性能下降。但目前来说，这些性能下降只会发生在第一次操作时，当以后对相同文件进行操作时将不会再次触发COW操作。&lt;/p&gt;
&lt;h2&gt;如何使用Data Volume&lt;/h2&gt;
&lt;p&gt;之前提过，当一个容器删除时，容器中所使用的R/W Layer也会随之被删除。那么容器中所产生的数据也会消失。如果用户需要保存这些数据，Docker建议使用Data Volume。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data Volume是一个直接挂载到Container之中的目录或者文件。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Data Volume不会被存储驱动所控制，这就意味着所有对Data Volume的读写操作都将跳过存储驱动，而直接通过host OS来完成。用户可以挂载任意多个data volume到一个container之中，也可以多个container共享同一份data volume。&lt;/p&gt;
&lt;p&gt;下图演示了两个Container同时挂载同一个Data Volume目录。&lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="https://lh3.googleusercontent.com/-uuuZMYFkWQk/VonUfwIIjYI/AAAAAAAAABI/FU8sZlZ3lsU/s757-Ic42/shared-volume.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;通过Data Volume可以减轻Container的"重量"，也可以当删除容器时保存其中有价值的数据。&lt;/p&gt;</summary></entry><entry><title>MockKoa - 一个基于Koa的API测试模拟服务器</title><link href="/mockkoa-yi-ge-ji-yu-koade-apice-shi-mo-ni-fu-wu-qi.html" rel="alternate"></link><updated>2016-01-02T00:00:00+08:00</updated><author><name>andy.zhangtao</name></author><id>tag:,2016-01-02:mockkoa-yi-ge-ji-yu-koade-apice-shi-mo-ni-fu-wu-qi.html</id><summary type="html">&lt;h1&gt;MockKoa － 一个基于Koa的API测试服务器&lt;/h1&gt;
&lt;p&gt;来自于andy的博客&lt;a href="&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#116;&amp;#111;&amp;#58;&amp;#97;&amp;#110;&amp;#100;&amp;#121;&amp;#46;&amp;#122;&amp;#104;&amp;#97;&amp;#110;&amp;#103;&amp;#116;&amp;#97;&amp;#111;&amp;#64;&amp;#104;&amp;#111;&amp;#116;&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#46;&amp;#99;&amp;#111;&amp;#109;"&gt;&amp;#97;&amp;#110;&amp;#100;&amp;#121;&amp;#46;&amp;#122;&amp;#104;&amp;#97;&amp;#110;&amp;#103;&amp;#116;&amp;#97;&amp;#111;&amp;#64;&amp;#104;&amp;#111;&amp;#116;&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#46;&amp;#99;&amp;#111;&amp;#109;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;MockKoa是什么？&lt;/h2&gt;
&lt;p&gt;MockKoa是一个基于Koa＋nodejs的Rest API的测试服务器，说成是框架也可以，但我认为距离框架还有一些距离。&lt;/p&gt;
&lt;p&gt;MockKoa使用nodejs来开发，通过Koa完成主要逻辑处理，可以加载以swagger为载体的API服务。(如果不了解swagger,&lt;a href="www.swagger.io"&gt;请点击这里&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;目前MockKoa仅仅支持swagger格式，未来会考虑支持Yaml格式，但目前还没有具体时间安排。&lt;/p&gt;
&lt;h2&gt;MockKoa可以做什么？&lt;/h2&gt;
&lt;p&gt;MockKoa最重要的功能就是按照模拟策略生成API返回值，针对用户发起的每个API请求都可以生成唯一准确并且满足用户预期的返回值。&lt;/p&gt;
&lt;p&gt;返回值包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;响应状态码&lt;/li&gt;
&lt;li&gt;响应body数据&lt;/li&gt;
&lt;li&gt;响应header数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;响应状态码&lt;/h4&gt;
&lt;p&gt;MockKoa可以根据用户设定的模拟策略来返回指定的状态码。MockKoa支持多种模拟策略，并且支持一定的逻辑处理，但MockKoa不会自动生成状态码，这些状态码仍然需要用户明确指定。指定的方式可以是通过swagger文件指定或者通过用户自定义代码指定。&lt;/p&gt;
&lt;p&gt;MockKoa在返回状态码时不会校验状态码是否有效，即便用户设定需要返回的响应码为601，MockKoa也会"乖顺"的返回此值。所以需要用户自行保证状态码是否有效。&lt;/p&gt;
&lt;p&gt;同时，MockKoa不会处理重定向请求。对于重定向请求，需要客户端来处理，MockKoa模拟的是服务端，所以不需要处理重定向请求(有一些用户问过此问题，所以补充此处说明)。&lt;/p&gt;
&lt;h4&gt;响应body数据&lt;/h4&gt;
&lt;p&gt;MockKoa可以根据用户设定的body数据返回。 MockKoa默认设定Content—Type为&lt;strong&gt;&lt;em&gt;*application/json&lt;/em&gt;&lt;/strong&gt;*(有些用户问过很多次，这次也补充上)。如果用户需要返回其他类型，请自行设定。假设用户使用的是swagger文件，那么可以通过下面的代码进行指定。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&amp;quot;examples&amp;quot;: {
              &amp;quot;application/json&amp;quot;: {
                &amp;quot;folderId&amp;quot;: 123456,
                &amp;quot;createAt&amp;quot;: &amp;quot;2015-06-19T14:36:30&amp;quot;,
                &amp;quot;size&amp;quot;: &amp;quot;10KB&amp;quot;
              }
            }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;MockKoa同样不会检查用户所设定的Content-type是否有效，假设用户设定的Content-type是：&lt;strong&gt;app/json&lt;/strong&gt;, MockKoa也会老老实实的返回。&lt;/p&gt;
&lt;p&gt;用户设定Body数据有两种方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过在examples中指定返回数据。（实例如上）&lt;/li&gt;
&lt;li&gt;通过在schema中指定返回数据。&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&amp;quot;definitions&amp;quot;: {
    &amp;quot;Pet&amp;quot;: {
      &amp;quot;properties&amp;quot;: {
        &amp;quot;name&amp;quot;: {
          &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;
        },
        &amp;quot;birthday&amp;quot;: {
          &amp;quot;type&amp;quot;: &amp;quot;integer&amp;quot;,
          &amp;quot;format&amp;quot;: &amp;quot;int32&amp;quot;
        },
        &amp;quot;company&amp;quot;: {
          &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;
        },
        &amp;quot;sex&amp;quot;: {
          &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;
        }
      }
    }
  } 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;MockKoa会自动生成5个Pet并且返回(5个是固定值，用户无法修改)。MockKoa在生成Pet时，会自动若干属性值，例如name，birthday，company，sex等等这些都会自动生成，除此之外，是会自动生成手机号(phone)，信用卡卡号(creditid)。但因为这些值都属于模拟计算得出，无法贴合实际情况，请用户知晓此点。&lt;/p&gt;
&lt;h4&gt;响应Header数据&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Header的处理未经充分测试，可能存在一些问题&lt;/strong&gt;。MockKoa会按照用户所设定的Header值返回指定的Header，但因为时间关系，这部分未经充分测试，在解析swagger文件时可能会出现用户多处定义Header信息，但MockKoa只会返回其中某一处Header的情况。&lt;/p&gt;
&lt;h2&gt;MockKoa有哪些模拟策略？&lt;/h2&gt;
&lt;p&gt;MockKoa目前有5种模拟策略：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;固定值返回。&lt;/li&gt;
&lt;li&gt;顺序返回。&lt;/li&gt;
&lt;li&gt;随机返回。&lt;/li&gt;
&lt;li&gt;按照不同权重返回。&lt;/li&gt;
&lt;li&gt;按照用户自定义逻辑返回。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;固定值返回&lt;/h4&gt;
&lt;p&gt;这种策略是最简单的策略，用户在swagger文件中，通过mockConfig.json文件指定需要返回的数据。MockKoa再收到指定的API请求时，会按图索骥检索到需返回的数据然后返回给用户。&lt;/p&gt;
&lt;p&gt;在使用这种策略时，用户需要保证mockConfig.json文件中所指定的数据一定在swagger文件中存在。&lt;/p&gt;
&lt;h4&gt;顺序返回&lt;/h4&gt;
&lt;p&gt;顺序返回策略比固定值策略跟进一步，假设用户为某个API设定了：“200”，“201”，“202”三种返回值。固定值只能三选一，返回一个。但顺序返回策略，可以依次返回。&lt;/p&gt;
&lt;p&gt;这种策略大多数应用于单元测试，可以依次测试用户端所有代码是否都可以获得预期结果。&lt;/p&gt;
&lt;h4&gt;随机返回&lt;/h4&gt;
&lt;p&gt;随机返回相较于前两种策略，更加贴近于线上情况。同样假设用户为某个API设定了：“200”，“400”，“500”，“504”四种返回值。 随机返回策略可以针对每次的网络请求，自动选择其中一种返回值返回。&lt;/p&gt;
&lt;p&gt;因此通过这种策略，可以基本满足QA环境中的测试需要。&lt;/p&gt;
&lt;p&gt;但在大数据量(&amp;gt;=100W)情景中，四种返回值总体返回概率几乎接近于1:1:1:1。如果400，500，504这样大量的出现，那么与实际线上情况会差距特别大。为了更加真实的接近线上情况，可以使用下面的模拟策略：&lt;/p&gt;
&lt;h4&gt;按照权重返回&lt;/h4&gt;
&lt;p&gt;我们为上述四种返回值设定不同的权重: 9:2:1:1。 同样经过100W网络请求下，MockKoa会返回69W次200，15W次400，500和504大致各出现8W次。以上数据均属于理论数据，按照统计数理论，每轮返回的数据都会有小幅波动，但总体出现比值会接近9:2:1:1。&lt;/p&gt;
&lt;p&gt;通过这种策略，用户可以根据预估的线上情况设定不同的权重，来满足UAT环境测试需要。&lt;/p&gt;
&lt;h2&gt;MockKoa有哪些不足？&lt;/h2&gt;
&lt;p&gt;MockKoa目前处于Bate阶段，功能还有待完善。同时MockKoa目前没有UI，所有配置只能通过mockConfig.json来完全配置，每次修改mockConfig.json之后都需要重启MockKoa。&lt;/p&gt;
&lt;p&gt;MockKoa UI Demo开发计划目前已经提上了开发日程，计划通过这个UI，可以让用户对MockKoa有个简单的认识，简化用户操作。&lt;/p&gt;
&lt;h2&gt;如何下载MockKoa？&lt;/h2&gt;
&lt;p&gt;用户可以通过访问&lt;a href="https://github.com/andy-zhangtao/MockKoa"&gt;我的github&lt;/a&gt;来获取最新的MockKoa。欢迎用户针对使用过程中发现的问题给我留言(&lt;a href="&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#116;&amp;#111;&amp;#58;&amp;#97;&amp;#110;&amp;#100;&amp;#121;&amp;#46;&amp;#122;&amp;#104;&amp;#97;&amp;#110;&amp;#103;&amp;#116;&amp;#97;&amp;#111;&amp;#64;&amp;#104;&amp;#111;&amp;#116;&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#46;&amp;#99;&amp;#111;&amp;#109;"&gt;&amp;#97;&amp;#110;&amp;#100;&amp;#121;&amp;#46;&amp;#122;&amp;#104;&amp;#97;&amp;#110;&amp;#103;&amp;#116;&amp;#97;&amp;#111;&amp;#64;&amp;#104;&amp;#111;&amp;#116;&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#46;&amp;#99;&amp;#111;&amp;#109;&lt;/a&gt;).&lt;/p&gt;</summary></entry></feed>