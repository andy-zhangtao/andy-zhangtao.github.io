<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>andy's blog</title><link href="/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>/</id><updated>2016-01-14T00:00:00+08:00</updated><entry><title>Linux常用命令</title><link href="/linuxchang-yong-ming-ling.html" rel="alternate"></link><updated>2016-01-14T00:00:00+08:00</updated><author><name>andy.zhangtao</name></author><id>tag:,2016-01-14:linuxchang-yong-ming-ling.html</id><summary type="html">&lt;h1&gt;Linux常用命令(TBC)&lt;/h1&gt;
&lt;h2&gt;删除邮件&lt;/h2&gt;
&lt;p&gt;&lt;br/&gt;
每次登录时都会显示"you have new mail"，挺烦人的。 执行下面的命令删除掉所有邮件:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;mail
? delete *
? q
&lt;/pre&gt;&lt;/div&gt;</summary></entry><entry><title>升级Docker 1.10遇到的小问题</title><link href="/sheng-ji-docker-110yu-dao-de-xiao-wen-ti.html" rel="alternate"></link><updated>2016-01-13T00:00:00+08:00</updated><author><name>andy.zhangtao</name></author><id>tag:,2016-01-13:sheng-ji-docker-110yu-dao-de-xiao-wen-ti.html</id><summary type="html">&lt;h1&gt;Docker升级到1.10遇到的小问题&lt;/h1&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;目前Docker最新开发版本为1.10，在1.10当中，Docker从内核层面做了很多重构。将以前偶合度较高的代码通过Interface进行了接耦合，代码逻辑关系变的非常清晰。
&lt;br/&gt;
在1.10版本中，docker主要改进了以下几个方面：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;支持使用plugin。(有了这个功能以后，估计开放docker插件的人就会非常多了)&lt;/li&gt;
&lt;li&gt;增强namespaces稳定性。&lt;/li&gt;
&lt;li&gt;重新编排了Remote API。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果用户想要尝鲜试用1.10，那么最简单的方式就是从github上面clone docker sourcecode，然后build。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;当启动docker 1.10之后，docker需要迁移旧版本的数据。 而本人恰恰在这个环节遇到了诡异的问题。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;起因&lt;/h2&gt;
&lt;p&gt;首先我来描述一下问题发生的步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;关闭旧版本的docker。 我没有通过service docker stop的方式停止，而是直接通过kill docker process的方式。(事后证明，这种方式相当错误)&lt;/li&gt;
&lt;li&gt;将旧版本的docker替换为docker 1.10。 &lt;/li&gt;
&lt;li&gt;正常启动docker 1.10. (如果是第一次启动，建议输出debug信息，方便失败后分析原因)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;然后问题就出现了，Docker daemon提示：xxxxxx container中的config.json不存在，daemon初始化失败。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;经过&lt;/h2&gt;
&lt;p&gt;按照以前使用docker的经验来看，是container的配置文件出了问题。因此，我首先判断以下方面是否正常：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;contaienr路径是否正常。(也就是验证一下这个路径是否存在，权限是否正确)&lt;/li&gt;
&lt;li&gt;daemon所读取的文件是否正常.(验证文件是否存在，文件内容是否正确，文件权限是否正确)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在验证第二条时发现，这个container目录虽然存在，但只是一个空目录，没有任何文件。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
再启动docker 1.9，发现一切正常。继续分析日志可以发现，这个错误是在docker 1.10执行migrate时报出的。那么也就是docker1.10需要将旧container数据结构转化为新的数据结构，在转换时发现config.json为空，因此报错退出。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;那么，目前需要明确：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;migrate是否是必须的步骤?&lt;/li&gt;
&lt;li&gt;migrate时是否每个container都要成功?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;从docker1.10的角度分析，新内核采取了新的数据结构，旧数据结构很可能支持度有限，那么迁移一定是需要做的。但是否每个container都需要迁移成功呢？
&lt;br/&gt;
正常情况下，每个contianer在创建时都会生成一系列的配置文件。如果某个container出现丢失配置文件的情况，那么只可能发生在create container时出现了异常，说的直白点就是：create container过程中，强行关闭了docker daemon，导致配置文件没有生成。(也就是上面所提到的强行kill的结果)&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
在这种情况下，因为这个container实际上没有对外提供任何服务，所以也可以认为这个container是可删的。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
那么就明确了，在迁移时不需要保证每个container都迁移成功。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
但这个问题应该如何处理呢？&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;结果&lt;/h2&gt;
&lt;p&gt;解决方案有两套：&lt;/p&gt;
&lt;p&gt;方案1.    删除空目录，也就是在container目录中删除那个创建失败的container。为什么这么做呢？因为分析完代码后发现，迁移代码就是遍历container目录，然后逐个container进行迁移。因此删除掉就恢复正常。&lt;/p&gt;
&lt;p&gt;方案2.    修改代码，当发现container迁移失败时，跳过此container，继续后面的工作。不能阻塞daemon初始化。这个方案是治根的方案。&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
方案1最简单，而方案2最稳妥。 目前我已经fix了这个defect，docker已经将这部分fix代码merge到了1.10版本中。重新clone 1.10的代码，然后重新build就可以彻底解决这个问题。&lt;/p&gt;</summary></entry><entry><title>如何在Mac上面搭建Docker开发环境</title><link href="/ru-he-zai-macshang-mian-da-jian-dockerkai-fa-huan-jing.html" rel="alternate"></link><updated>2016-01-06T15:03:00+08:00</updated><author><name>andy.zhangtao</name></author><id>tag:,2016-01-06:ru-he-zai-macshang-mian-da-jian-dockerkai-fa-huan-jing.html</id><summary type="html">&lt;h1&gt;如何在Mac上面搭建Docker开发环境&lt;/h1&gt;
&lt;p&gt;按照欧美技术范儿来说，开发机器十有八九都是Mac。Docker开发应该也是在Mac上面进行的，所以一开始认为直接从git上面clone docker src，然后执行make应该就大功告成。但中间还是遇到了一些挫折，所以我把过程提供出来以供以后查询备用。&lt;/p&gt;
&lt;h3&gt;从git上面clone是第一步&lt;/h3&gt;
&lt;p&gt;首先需要从git上面clone Docker source code。 Git地址是：https://github.com/docker/docker.git。
这一步就是耗费时间，只要网络不断应该就没有问题。&lt;/p&gt;
&lt;h3&gt;在本地Mac上面安装Docker&lt;/h3&gt;
&lt;p&gt;这一步后面命令执行成功的前提。因为后面所有的步骤都是基于Docker Image执行的。所以本地一定要有Docker运行环境。因为Docker目前还不支持在原生Mac os上面执行，所以想要借助于Virtualbox来实现。 具体安装步骤可参考&lt;a href="https://docs.docker.com/engine/installation/mac/"&gt;&amp;lt;如何在Mac上面运行Docker&amp;gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;检测storage.googleapis.com是否可访问&lt;/h3&gt;
&lt;p&gt;Docker需要从storage.googleapis.com这里下载go的最新版本。但这个域名处于BFW监控之中，所以在大陆境内很有可能无法访问。当前此域名对应IP是216.58.197.112。 所以我的处理方法是修改Dockerfile，直接修改hosts文件。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;RUN echo 216.58.197.112  storage.googleapis.com &amp;gt;&amp;gt; /etc/hosts;curl -sSL  &amp;quot;https://storage.googleapis.com/golang/go&lt;span class="cp"&gt;${&lt;/span&gt;&lt;span class="n"&gt;GO_VERSION&lt;/span&gt;&lt;span class="cp"&gt;}&lt;/span&gt;.linux-amd64.tar.gz&amp;quot; | tar -v -C /usr/local -xz
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;执行Makefile&lt;/h3&gt;
&lt;p&gt;到这里，就可以通过make命令来执行Makfile了。 如果是在大陆境内，这一步非常耗时。但理论上来说应该是不会报错的。所以干点别的去吧，大概在1个小时之后再回来看看结果。&lt;/p&gt;
&lt;h3&gt;设定BINDDIR&lt;/h3&gt;
&lt;p&gt;即便上面那一步执行成功了，你也无法看到Docker可执行程序。这是因为下面的语句所造成的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;BIND_DIR&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;BINDDIR&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;BINDDIR&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;DOCKER_HOST&lt;span class="k"&gt;)&lt;/span&gt;,,bundles&lt;span class="k"&gt;))&lt;/span&gt;
&lt;span class="nv"&gt;DOCKER_MOUNT&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;BIND_DIR&lt;span class="k"&gt;)&lt;/span&gt;,-v &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;CURDIR&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;BIND_DIR&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;:/go/src/github.com/docker/docker/&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;BIND_DIR&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;BIND_DIR是编译后的目标目录。如果BINDDIR没有设置，那么就会通过$(if $(DOCKER_HOST),,bundles)来判断。&lt;/p&gt;
&lt;p&gt;$(if $(DOCKER_HOST),,bundles)的意思是如果DOCKER_HOST有值，那么就返回空，如果没有值就返回bundles。&lt;/p&gt;
&lt;p&gt;问题就出在这里，因为当前环境是Mac OS。而为了可以执行此Makefile脚本，就需要在Mac中运行Docker。如此一来，就一定会出现DOCKER_HOST变量。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;echo &lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;DOCKER_HOST&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;tcp://192.168.99.100:2376&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这样BIND_DIR就为空。因此就不会挂载任何目录到编译Container之中，所以即便编译成功了，也不会输出任何可执行程序。&lt;/p&gt;
&lt;p&gt;解决方案有三个：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;设定BINDDIR。 BINDDIR := bundles&lt;/li&gt;
&lt;li&gt;当DOCKER_HOST有值时返回bundles。 if $(DOCKER_HOST),bundles,&lt;/li&gt;
&lt;li&gt;在make中设定值。make BIND_DIR=bundles&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;然后再执行make，就可以在bundles目录中看到最终的可执行程序了。&lt;/p&gt;</summary></entry><entry><title>Docker输出日志的几种方式</title><link href="/dockershu-chu-ri-zhi-de-ji-chong-fang-shi.html" rel="alternate"></link><updated>2016-01-04T21:51:00+08:00</updated><author><name>andy.zhangtao</name></author><id>tag:,2016-01-04:dockershu-chu-ri-zhi-de-ji-chong-fang-shi.html</id><summary type="html">&lt;h1&gt;Docker输出日志的几种方式&lt;/h1&gt;
&lt;p&gt;在使用Docker过程中，查看日志是必不可少的一项工作。通过Docker提供的docker logs命令可以查看指定容器所输出的日志。但此命令有一些限制范围，当前docker logs命令仅仅只能支持json-file,journald这两种日志驱动，如果container使用其它类型的日志驱动，那么logs命令将无法提取日志。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;那么如何查看容器所输出的日志呢？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了解决这个问题，我们首先来看看Docker都支持哪些类型的日志驱动。&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;Docker支持的日志驱动类型&lt;/h2&gt;
&lt;p&gt;Docker目前支持以下类型的驱动：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;驱动名称&lt;/th&gt;
&lt;th&gt;是否支持logs&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;json-file&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;journald&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;syslog&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;gelf&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;fluentd&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;awslogs&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;Docker如何指定日志驱动？&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;指定日志驱动有两种方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过Daemon指定全局默认日志驱动&lt;/li&gt;
&lt;li&gt;通过Run命令指定特定日志驱动&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果需要指定全局默认日志驱动，可以在启动Docker Daemon时指定，命令如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;docker daemon --log-driver=json-file --log-opt labels=foo --log-opt env=foo,fizz
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;当执行完这条命令之后，以后所有新创建的Container都默认使用json-file来保存日志。这就是全局默认模式。如果需要给特定的Container指定日志驱动，那么就可以参考下面的命令：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;docker run --log-driver&lt;span class="o"&gt;=&lt;/span&gt;syslog --log-opt syslog-address&lt;span class="o"&gt;=&lt;/span&gt;tcp://192.168.0.42:123 ubuntu
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;各个日志驱动的用法&lt;/h2&gt;
&lt;hr /&gt;
&lt;h3&gt;Json-file 驱动&lt;/h3&gt;
&lt;p&gt;Json-file驱动有四个配置参数(以下参数均通过--log-opt设置)：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;参数名称&lt;/th&gt;
&lt;th&gt;参数说明&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;max-size&lt;/td&gt;
&lt;td&gt;[0-9+][k\&lt;/td&gt;
&lt;td&gt;m\&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max-file&lt;/td&gt;
&lt;td&gt;[0-9+]&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;labels&lt;/td&gt;
&lt;td&gt;label1,label2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;env&lt;/td&gt;
&lt;td&gt;env1,env2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;max-size用于设置日志文件大小，单位为k，m和g。例如--log-opt max-size＝50m，可以将日志文件设置为50mb。当日志文件超过50mb之后，Docker将会重新生成新日志文件。如果max-size没有设置，那么Docker将永远不会生成新日志文件。&lt;/p&gt;
&lt;p&gt;max-file用于设置日志文件数量。例如--log-opt max-file=100。Docker将只会保存最后100个日志文件。如果max-file没有设置，那么Docker将会保存所有的日志文件。&lt;/p&gt;
&lt;p&gt;labels和env用于设置日志标签。&lt;/p&gt;
&lt;h3&gt;syslog 驱动&lt;/h3&gt;
&lt;p&gt;Docker可以将日志发送到syslog服务器(因为syslog服务器兼容rsyslog服务器，所以Docker也可将日志分送至rsyslog server)。&lt;/p&gt;
&lt;p&gt;syslog可使用的参数如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;--log-opt syslog-address=[tcp|udp]://host:port
--log-opt syslog-address=unix://path
--log-opt syslog-facility=daemon
--log-opt tag=&amp;quot;mailer&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;syslog-address用来设置syslog(rsyslogd)server的IP和端口。 syslog-facility用来设置发送设备名称，目前可以设置的设备名称如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kern&lt;/li&gt;
&lt;li&gt;user&lt;/li&gt;
&lt;li&gt;mail&lt;/li&gt;
&lt;li&gt;daemon&lt;/li&gt;
&lt;li&gt;auth&lt;/li&gt;
&lt;li&gt;syslog&lt;/li&gt;
&lt;li&gt;lpr&lt;/li&gt;
&lt;li&gt;news&lt;/li&gt;
&lt;li&gt;uucp&lt;/li&gt;
&lt;li&gt;cron&lt;/li&gt;
&lt;li&gt;authpriv&lt;/li&gt;
&lt;li&gt;ftp&lt;/li&gt;
&lt;li&gt;local0&lt;/li&gt;
&lt;li&gt;local1&lt;/li&gt;
&lt;li&gt;local2&lt;/li&gt;
&lt;li&gt;local3&lt;/li&gt;
&lt;li&gt;local4&lt;/li&gt;
&lt;li&gt;local5&lt;/li&gt;
&lt;li&gt;local6&lt;/li&gt;
&lt;li&gt;local7&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;默认情况下，Docker使用Container short name作为日志标记名称，但用户也可以通过tag来重命名此名称。&lt;/p&gt;
&lt;h3&gt;journald 驱动&lt;/h3&gt;
&lt;p&gt;如果用户指定了journald驱动，Docker将会把所有日志发送到Docker.service日志中(默认情况)。用户可以通过journalctl 来筛选日志。&lt;/p&gt;
&lt;h3&gt;gelf 驱动&lt;/h3&gt;
&lt;p&gt;gelf驱动的使用方式和syslog的使用方式类似，可搭配的参数如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;--log-opt gelf-address=udp://host:port
--log-opt tag=&amp;quot;database&amp;quot;
--log-opt labels=label1,label2
--log-opt env=env1,env2
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;fluentd 驱动&lt;/h3&gt;
&lt;p&gt;在使用fluentd驱动时需要注意一点，如果用户所指定的fluentd服务器地址不可达，那么此容器将会报错退出。而其它驱动则不会出现这种情况。&lt;/p&gt;
&lt;p&gt;使用fluentd驱动的命令如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;docker run --log-driver=fluentd --log-opt fluentd-address=localhost:24224 --log-opt tag=docker.&lt;/span&gt;&lt;span class="cp"&gt;{{&lt;/span&gt;&lt;span class="nv"&gt;.Name&lt;/span&gt;&lt;span class="cp"&gt;}}&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;aws logs驱动&lt;/h3&gt;
&lt;p&gt;AWS驱动使用目前不太普遍，所以下面仅提供使用参数：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;--log-opt awslogs-region=&amp;lt;aws_region&amp;gt;
--log-opt awslogs-group=&amp;lt;log_group_name&amp;gt;
--log-opt awslogs-stream=&amp;lt;log_stream_name&amp;gt;
&lt;/pre&gt;&lt;/div&gt;</summary></entry><entry><title>Docker 如何管理Image,Container</title><link href="/docker-ru-he-guan-li-imagecontainer.html" rel="alternate"></link><updated>2016-01-04T00:00:00+08:00</updated><author><name>andy.zhangtao</name></author><id>tag:,2016-01-04:docker-ru-he-guan-li-imagecontainer.html</id><summary type="html">&lt;h1&gt;Docker 如何管理Image,Container？&lt;/h1&gt;
&lt;p&gt;在使用Docker之前，有一个问题始终无法回避：Docker如何高效的管理和使用Image和Container数据？
为了搞明白这个问题，我们首先需要理解：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Docker如何构建和存储Image？&lt;/li&gt;
&lt;li&gt;Docker如何基于Image来创建Container？&lt;/li&gt;
&lt;li&gt;Docker如何操作Image和Container？&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Image和Container的基础 － Layers(文件层)&lt;/h2&gt;
&lt;p&gt;从数据结构上面来看，Docker当中所有的Image都是一系列&lt;strong&gt;有序&lt;/strong&gt;只读(Read-Only)文件层(Layers)的集合。位于这个集合最顶端的文件层，我们称之为BaseImage。其它文件层都依赖于它。下图是一个Ubuntu15.04的Image示意图，这个Image包含了4个文件层。
&lt;img alt="image" src="https://lh3.googleusercontent.com/-D8MQPkSpeb8/VonUe0SEWKI/AAAAAAAAAAw/NXLg19gDpq4/s448-Ic42/image-layers.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;当用户在这个Container中做任何写操作时，例如：在/tmp目录中新创建一个文件，Docker就会在这个集合最下面再创建一个文件层来保存这种变化。Docker当中每个文件层都有一个唯一ID(UUID)，并且每个文件层都会记录其所依赖的文件层信息。&lt;/p&gt;
&lt;p&gt;Image都是由Layers组成的，与此相对应的，所有的Container也同样是由Layers组成的。但Container与Image又一个本质区别，组成Image的Layer都是RO，而组成Container的Layer中，处于最低端的Layer是RW，其它Layer都是RO。这个RW的Layer，我们称之为Thin R/W Layer。如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="https://lh3.googleusercontent.com/-z4JVQrV79zw/VonUe_iczQI/AAAAAAAAABE/KIr8ecUp4pM/s675-Ic42/container-layers.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Image和Container本质的区别就在于这个R/W Layer。在Container当中所发生的所有写操作，都会被如实的纪录在此Layer之中。当Container被删除之后，这个Layer也会被随之删除。而Container所依赖的Image Layer集合则不会被删除。因此，Container可以理解为：&lt;strong&gt;Container=Image＋RW Layer&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;而正因为每个Container都有一个唯一的RW Layer，这就意味着多个Container可以共享同一份Image，并且可以保存其各自数据。下图显示多个Container如何共享同一份Image。
&lt;img alt="image" src="https://lh3.googleusercontent.com/-QyW-QTY2if4/VonUgIVxhcI/AAAAAAAAABM/CCQeIem92IE/s769-Ic42/sharing-layers.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Docker通过两种技术来高效的使用Image和Container，一是：Layer依赖，二是：写时复制(Copy-on-Write)。本节当中，我们介绍的是Layer依赖。下节我们将会介绍写时复制。&lt;/p&gt;
&lt;h2&gt;写时复制(Copy-on-Write)&lt;/h2&gt;
&lt;p&gt;通过资源共享可以很好的利用当前资源。这种方式不仅仅发生在数字世界当中，在人类实际情况中也经常发生。&lt;/p&gt;
&lt;p&gt;例如：我们假设目前有一对双胞胎，阿猫和阿狗(权当他俩是双胞胎)。两个双胞胎在不同的班级上学，某一天两人的老师分别留了相同的作业。阿猫很快的写完了作业，而阿狗则贪玩没有写。第二天需要交作业时，因为是同一个老师上课，而俩人又不在同一个班级，因此交作业的时间就可以错开。阿猫先交作业，老师审核没问题，作业就还给了阿猫(我们假设老师没有做任何批改)。然后阿猫在下课时将作业给了阿狗，那么阿狗就可以使用同一份作业来糊弄老师。如此一来，两个人只写了一份作业，就通过了两次审核，为国家绿色环保做了贡献。&lt;/p&gt;
&lt;p&gt;写时复制就是上面过程的数字化。在写时复制策略中，需要数据的进程仅仅只需要使用目前已经存在的数据就可以，而不是在重新拷贝复制一份。只有这个进程需要修改数据了，才会单独拷贝一份，除此之外完全不需要单独保存数据。&lt;/p&gt;
&lt;p&gt;Docker通过COW策略来管理Image和Container数据。通过COW策略，Docker可以更高效的利用磁盘空间和网络带宽资源。下一节，我们来看看COW策略是如何在Docker中应用的。&lt;/p&gt;
&lt;h2&gt;COW在Docker中的应用&lt;/h2&gt;
&lt;p&gt;本节，我们聚焦于Docker如何通过COW策略来管理Image和Container。首先，我们引入两个命令:pull和push。 通过Docker pull命令，我们可以从远程仓库获取一个Image。例如下图所示：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;docker pull ubuntu:15.04
15.04: Pulling from library/ubuntu
6e6a100fa147: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
13c0c663a321: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
2bd276ed39d5: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
013f3d01d247: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
Digest: sha256:c7ecf33cef00ae34b131605c31486c91f5fd9a76315d075db2afd39d1ccdf3ed
Status: Downloaded newer image &lt;span class="k"&gt;for&lt;/span&gt; ubuntu:15.04
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;通过命令输出可以看到，Ubuntu15.04包含有四个Layer。这四个Layer组合起来才是一个完整的Ubuntu15.04 Image。所有的Image数据都是保存在本地，默认情况下是在/var/lib/docker目录之中。取决于不同的存储驱动，数据保存在docker目录中不同的子目录之中。&lt;/p&gt;
&lt;p&gt;如果我们假设目前使用的是AUFS存储驱动，那么可以通过下面的命令来查看下载到的Layer数据：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;sudo ls /var/lib/docker/aufs/layers
013f3d01d24738964bb7101fa83a926181d600ebecca7206dced59669e6e6778  2bd276ed39d5fcfd3d00ce0a190beeea508332f5aec3c6a125cc619a3fdbade6
13c0c663a321cd83a97f4ce1ecbaf17c2ba166527c3b06daaefe30695c5fcb8c  6e6a100fa147e6db53b684c8516e3e2588b160fd4898b6265545d5d4edb6796d
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;如果用户再下载另外一个基于Ubuntu15.04的Image，那么Docker就只会下载当前本地目录中没有的Layer数据，已经下载的这4个Layer则不会重复下载。&lt;/p&gt;
&lt;p&gt;我们可以通过下面的实例来演示这个过程。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先通过创建一个Dockerfile来引入Ubuntu15.04&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;FROM ubuntu:15.04
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;我们在新Image中的创建一个文件，并且写入Hello World。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;FROM ubuntu:15.04

RUN echo &amp;quot;Hello world&amp;quot; &amp;gt; /tmp/newfile
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;保存Dockerfile。然后开始构建新Image：&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    $ docker build -t changed-ubuntu .
    Sending build context to Docker daemon 2.048 kB
    Step 0 : FROM ubuntu:15.04
    ---&amp;gt; 013f3d01d247
    Step 1 : RUN echo &amp;quot;Hello world&amp;quot; &amp;gt; /tmp/newfile
    ---&amp;gt; Running in 2023460815df
    ---&amp;gt; 03b964f68d06
    Removing intermediate container 2023460815df
    Successfully built 03b964f68d06
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;通过Docker image命令，我们可以查看到构建成功的Image：&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE

changed-ubuntu      latest              03b964f68d06        33 seconds ago      131.4 MB  
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;通过Docker history命令来查看当前Image所包含的Layer集合。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    $ docker history changed-ubuntu
    IMAGE               CREATED              CREATED BY                                    SIZE           COMMENT
    03b964f68d06        About a minute ago   /bin/sh -c echo &amp;quot;Hello world&amp;quot; &amp;gt; /tmp/newfile    12 B                
    013f3d01d247        6 weeks ago          /bin/sh -c #(nop) CMD [&amp;quot;/bin/bash&amp;quot;]             0 B                 
    2bd276ed39d5        6 weeks ago          /bin/sh -c sed -i &amp;#39;s/^#\s*\(deb.*universe\)$/   1.879 kB            
    13c0c663a321        6 weeks ago          /bin/sh -c echo &amp;#39;#!/bin/sh&amp;#39; &amp;gt; /usr/sbin/polic   701 B               
    6e6a100fa147        6 weeks ago          /bin/sh -c #(nop) ADD file:49710b44e2ae0edef4   131.4 MB            
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;通过Docker history命令可以看到目前处于Layer集合最底层的Layer(03b964f68d06)就是我们通过"echo "Hello world" &amp;gt; /tmp/newfile"所创建的。 而其它四个Layer则是Ubuntu15.04所包含的4个Layer。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我们通过查看目录来验证是否又单独拷贝了另外4个Layer。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    $ sudo ls /var/lib/docker/aufs/layers
    013f3d01d24738964bb7101fa83a926181d600ebecca7206dced59669e6e6778    2bd276ed39d5fcfd3d00ce0a190beeea508332f5aec3c6a125cc619a3fdbade6
    03b964f68d06a373933bd6d61d37610a34a355c168b08dfc604f57b20647e073    6e6a100fa147e6db53b684c8516e3e2588b160fd4898b6265545d5d4edb6796d
    13c0c663a321cd83a97f4ce1ecbaf17c2ba166527c3b06daaefe30695c5fcb8c
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;通过检查实际目录数据可以看到，当前文件系统中只有5个目录。因此，也就说明了，通过刚才的操作，虽然创建了一个新Image，但Docker并未完全拷贝所有Layer，而仅仅是创建了一个Layer。这个过程可以用下图来表示：&lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="https://lh3.googleusercontent.com/-I3jpGPoQeYM/VonUfB8x7iI/AAAAAAAAAA0/qx5XSS9nTrw/s757-Ic42/saving-space.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;通过COW策略，Docker可以高效利用磁盘空间，避免重复保存多余数据。&lt;/p&gt;
&lt;h2&gt;通过COW策略可以高效使用Container&lt;/h2&gt;
&lt;p&gt;我们在前面提到过，每一个Container最底层都有一个Thin R/W Layer。&lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="https://lh3.googleusercontent.com/-z4JVQrV79zw/VonUe_iczQI/AAAAAAAAABE/KIr8ecUp4pM/s675-Ic42/container-layers.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Container当中所有的写操作都被保存在这个Layer之中，而其它RO Layer则无法被修改。通过这种策略，多个Container可以共享使用同一份Layer集合。下图演示同时基于Ubuntu15.04创建多个Container，每个Container都有各自的RW Layer。&lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="https://lh3.googleusercontent.com/-QyW-QTY2if4/VonUgIVxhcI/AAAAAAAAABM/CCQeIem92IE/s769-Ic42/sharing-layers.jpg" /&gt;       &lt;/p&gt;
&lt;p&gt;当容器当中发生写操作时，Docker会触发一个COW操作。具体的COW处理则依赖于具体的存储驱动，AUFS和BTFS的处理方式就各不相同。&lt;/p&gt;
&lt;p&gt;如果容器需要保存大量数据，那么Docker推荐将这些数据通过data volume来保存，而不建议直接将这些数据写入RW Layer。因为通过COW操作来保存数据时，会出现明显的性能下降。而下降的程度则取决于当前Docker所使用的存储驱动方式。通常来说，保存大文件，保存多个Layer和保存多层级的目录树都会引起性能下降。但目前来说，这些性能下降只会发生在第一次操作时，当以后对相同文件进行操作时将不会再次触发COW操作。&lt;/p&gt;
&lt;h2&gt;如何使用Data Volume&lt;/h2&gt;
&lt;p&gt;之前提过，当一个容器删除时，容器中所使用的R/W Layer也会随之被删除。那么容器中所产生的数据也会消失。如果用户需要保存这些数据，Docker建议使用Data Volume。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data Volume是一个直接挂载到Container之中的目录或者文件。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Data Volume不会被存储驱动所控制，这就意味着所有对Data Volume的读写操作都将跳过存储驱动，而直接通过host OS来完成。用户可以挂载任意多个data volume到一个container之中，也可以多个container共享同一份data volume。&lt;/p&gt;
&lt;p&gt;下图演示了两个Container同时挂载同一个Data Volume目录。&lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="https://lh3.googleusercontent.com/-uuuZMYFkWQk/VonUfwIIjYI/AAAAAAAAABI/FU8sZlZ3lsU/s757-Ic42/shared-volume.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;通过Data Volume可以减轻Container的"重量"，也可以当删除容器时保存其中有价值的数据。&lt;/p&gt;</summary></entry><entry><title>MockKoa - 一个基于Koa的API测试模拟服务器</title><link href="/mockkoa-yi-ge-ji-yu-koade-apice-shi-mo-ni-fu-wu-qi.html" rel="alternate"></link><updated>2016-01-02T00:00:00+08:00</updated><author><name>andy.zhangtao</name></author><id>tag:,2016-01-02:mockkoa-yi-ge-ji-yu-koade-apice-shi-mo-ni-fu-wu-qi.html</id><summary type="html">&lt;h1&gt;MockKoa － 一个基于Koa的API测试服务器&lt;/h1&gt;
&lt;p&gt;来自于andy的博客&lt;a href="&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#116;&amp;#111;&amp;#58;&amp;#97;&amp;#110;&amp;#100;&amp;#121;&amp;#46;&amp;#122;&amp;#104;&amp;#97;&amp;#110;&amp;#103;&amp;#116;&amp;#97;&amp;#111;&amp;#64;&amp;#104;&amp;#111;&amp;#116;&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#46;&amp;#99;&amp;#111;&amp;#109;"&gt;&amp;#97;&amp;#110;&amp;#100;&amp;#121;&amp;#46;&amp;#122;&amp;#104;&amp;#97;&amp;#110;&amp;#103;&amp;#116;&amp;#97;&amp;#111;&amp;#64;&amp;#104;&amp;#111;&amp;#116;&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#46;&amp;#99;&amp;#111;&amp;#109;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;MockKoa是什么？&lt;/h2&gt;
&lt;p&gt;MockKoa是一个基于Koa＋nodejs的Rest API的测试服务器，说成是框架也可以，但我认为距离框架还有一些距离。&lt;/p&gt;
&lt;p&gt;MockKoa使用nodejs来开发，通过Koa完成主要逻辑处理，可以加载以swagger为载体的API服务。(如果不了解swagger,&lt;a href="www.swagger.io"&gt;请点击这里&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;目前MockKoa仅仅支持swagger格式，未来会考虑支持Yaml格式，但目前还没有具体时间安排。&lt;/p&gt;
&lt;h2&gt;MockKoa可以做什么？&lt;/h2&gt;
&lt;p&gt;MockKoa最重要的功能就是按照模拟策略生成API返回值，针对用户发起的每个API请求都可以生成唯一准确并且满足用户预期的返回值。&lt;/p&gt;
&lt;p&gt;返回值包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;响应状态码&lt;/li&gt;
&lt;li&gt;响应body数据&lt;/li&gt;
&lt;li&gt;响应header数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;响应状态码&lt;/h4&gt;
&lt;p&gt;MockKoa可以根据用户设定的模拟策略来返回指定的状态码。MockKoa支持多种模拟策略，并且支持一定的逻辑处理，但MockKoa不会自动生成状态码，这些状态码仍然需要用户明确指定。指定的方式可以是通过swagger文件指定或者通过用户自定义代码指定。&lt;/p&gt;
&lt;p&gt;MockKoa在返回状态码时不会校验状态码是否有效，即便用户设定需要返回的响应码为601，MockKoa也会"乖顺"的返回此值。所以需要用户自行保证状态码是否有效。&lt;/p&gt;
&lt;p&gt;同时，MockKoa不会处理重定向请求。对于重定向请求，需要客户端来处理，MockKoa模拟的是服务端，所以不需要处理重定向请求(有一些用户问过此问题，所以补充此处说明)。&lt;/p&gt;
&lt;h4&gt;响应body数据&lt;/h4&gt;
&lt;p&gt;MockKoa可以根据用户设定的body数据返回。 MockKoa默认设定Content—Type为&lt;strong&gt;&lt;em&gt;*application/json&lt;/em&gt;&lt;/strong&gt;*(有些用户问过很多次，这次也补充上)。如果用户需要返回其他类型，请自行设定。假设用户使用的是swagger文件，那么可以通过下面的代码进行指定。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&amp;quot;examples&amp;quot;: {
              &amp;quot;application/json&amp;quot;: {
                &amp;quot;folderId&amp;quot;: 123456,
                &amp;quot;createAt&amp;quot;: &amp;quot;2015-06-19T14:36:30&amp;quot;,
                &amp;quot;size&amp;quot;: &amp;quot;10KB&amp;quot;
              }
            }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;MockKoa同样不会检查用户所设定的Content-type是否有效，假设用户设定的Content-type是：&lt;strong&gt;app/json&lt;/strong&gt;, MockKoa也会老老实实的返回。&lt;/p&gt;
&lt;p&gt;用户设定Body数据有两种方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过在examples中指定返回数据。（实例如上）&lt;/li&gt;
&lt;li&gt;通过在schema中指定返回数据。&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&amp;quot;definitions&amp;quot;: {
    &amp;quot;Pet&amp;quot;: {
      &amp;quot;properties&amp;quot;: {
        &amp;quot;name&amp;quot;: {
          &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;
        },
        &amp;quot;birthday&amp;quot;: {
          &amp;quot;type&amp;quot;: &amp;quot;integer&amp;quot;,
          &amp;quot;format&amp;quot;: &amp;quot;int32&amp;quot;
        },
        &amp;quot;company&amp;quot;: {
          &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;
        },
        &amp;quot;sex&amp;quot;: {
          &amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;
        }
      }
    }
  } 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;MockKoa会自动生成5个Pet并且返回(5个是固定值，用户无法修改)。MockKoa在生成Pet时，会自动若干属性值，例如name，birthday，company，sex等等这些都会自动生成，除此之外，是会自动生成手机号(phone)，信用卡卡号(creditid)。但因为这些值都属于模拟计算得出，无法贴合实际情况，请用户知晓此点。&lt;/p&gt;
&lt;h4&gt;响应Header数据&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Header的处理未经充分测试，可能存在一些问题&lt;/strong&gt;。MockKoa会按照用户所设定的Header值返回指定的Header，但因为时间关系，这部分未经充分测试，在解析swagger文件时可能会出现用户多处定义Header信息，但MockKoa只会返回其中某一处Header的情况。&lt;/p&gt;
&lt;h2&gt;MockKoa有哪些模拟策略？&lt;/h2&gt;
&lt;p&gt;MockKoa目前有5种模拟策略：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;固定值返回。&lt;/li&gt;
&lt;li&gt;顺序返回。&lt;/li&gt;
&lt;li&gt;随机返回。&lt;/li&gt;
&lt;li&gt;按照不同权重返回。&lt;/li&gt;
&lt;li&gt;按照用户自定义逻辑返回。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;固定值返回&lt;/h4&gt;
&lt;p&gt;这种策略是最简单的策略，用户在swagger文件中，通过mockConfig.json文件指定需要返回的数据。MockKoa再收到指定的API请求时，会按图索骥检索到需返回的数据然后返回给用户。&lt;/p&gt;
&lt;p&gt;在使用这种策略时，用户需要保证mockConfig.json文件中所指定的数据一定在swagger文件中存在。&lt;/p&gt;
&lt;h4&gt;顺序返回&lt;/h4&gt;
&lt;p&gt;顺序返回策略比固定值策略跟进一步，假设用户为某个API设定了：“200”，“201”，“202”三种返回值。固定值只能三选一，返回一个。但顺序返回策略，可以依次返回。&lt;/p&gt;
&lt;p&gt;这种策略大多数应用于单元测试，可以依次测试用户端所有代码是否都可以获得预期结果。&lt;/p&gt;
&lt;h4&gt;随机返回&lt;/h4&gt;
&lt;p&gt;随机返回相较于前两种策略，更加贴近于线上情况。同样假设用户为某个API设定了：“200”，“400”，“500”，“504”四种返回值。 随机返回策略可以针对每次的网络请求，自动选择其中一种返回值返回。&lt;/p&gt;
&lt;p&gt;因此通过这种策略，可以基本满足QA环境中的测试需要。&lt;/p&gt;
&lt;p&gt;但在大数据量(&amp;gt;=100W)情景中，四种返回值总体返回概率几乎接近于1:1:1:1。如果400，500，504这样大量的出现，那么与实际线上情况会差距特别大。为了更加真实的接近线上情况，可以使用下面的模拟策略：&lt;/p&gt;
&lt;h4&gt;按照权重返回&lt;/h4&gt;
&lt;p&gt;我们为上述四种返回值设定不同的权重: 9:2:1:1。 同样经过100W网络请求下，MockKoa会返回69W次200，15W次400，500和504大致各出现8W次。以上数据均属于理论数据，按照统计数理论，每轮返回的数据都会有小幅波动，但总体出现比值会接近9:2:1:1。&lt;/p&gt;
&lt;p&gt;通过这种策略，用户可以根据预估的线上情况设定不同的权重，来满足UAT环境测试需要。&lt;/p&gt;
&lt;h2&gt;MockKoa有哪些不足？&lt;/h2&gt;
&lt;p&gt;MockKoa目前处于Bate阶段，功能还有待完善。同时MockKoa目前没有UI，所有配置只能通过mockConfig.json来完全配置，每次修改mockConfig.json之后都需要重启MockKoa。&lt;/p&gt;
&lt;p&gt;MockKoa UI Demo开发计划目前已经提上了开发日程，计划通过这个UI，可以让用户对MockKoa有个简单的认识，简化用户操作。&lt;/p&gt;
&lt;h2&gt;如何下载MockKoa？&lt;/h2&gt;
&lt;p&gt;用户可以通过访问&lt;a href="https://github.com/andy-zhangtao/MockKoa"&gt;我的github&lt;/a&gt;来获取最新的MockKoa。欢迎用户针对使用过程中发现的问题给我留言(&lt;a href="&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#116;&amp;#111;&amp;#58;&amp;#97;&amp;#110;&amp;#100;&amp;#121;&amp;#46;&amp;#122;&amp;#104;&amp;#97;&amp;#110;&amp;#103;&amp;#116;&amp;#97;&amp;#111;&amp;#64;&amp;#104;&amp;#111;&amp;#116;&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#46;&amp;#99;&amp;#111;&amp;#109;"&gt;&amp;#97;&amp;#110;&amp;#100;&amp;#121;&amp;#46;&amp;#122;&amp;#104;&amp;#97;&amp;#110;&amp;#103;&amp;#116;&amp;#97;&amp;#111;&amp;#64;&amp;#104;&amp;#111;&amp;#116;&amp;#109;&amp;#97;&amp;#105;&amp;#108;&amp;#46;&amp;#99;&amp;#111;&amp;#109;&lt;/a&gt;).&lt;/p&gt;</summary></entry></feed>